<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Book Reading: CSAPP, Chapter 2, 整数的表示和运算</title>
    <url>/2021/05/12/book_reading_csapp_2_integer/</url>
    <content><![CDATA[<h2 id="整数的表示"><a href="#整数的表示" class="headerlink" title="整数的表示"></a>整数的表示</h2><h3 id="无符号数与有符号数"><a href="#无符号数与有符号数" class="headerlink" title="无符号数与有符号数"></a>无符号数与有符号数</h3><p>无符号数的表示非常直接，因为没有符号，k位的二进制就表示0 ~ 2<sup>k</sup> - 1范围内的整数。对于 [x<sub>k - 1</sub>, x<sub>k - 2</sub>, …, x<sub>0</sub>]，其表示的值为：<br><a id="more"></a></p>
<p><img src="/images/csapp_2_integer_0.png" alt></p>
<p>有符号因为存在负数的原因，其是用补码表示的。具体来说，其最高有效位的权重是负的，同样对于[x<sub>k - 1</sub>, x<sub>k - 2</sub>, …, x<sub>0</sub>]来说，其表示的值为:</p>
<p><img src="/images/csapp_2_integer_1.png" alt></p>
<p>对于k位的二进制，其表示的有符号数的范围是-2<sup>k - 1</sup> ~ 2<sup>k - 1</sup> - 1。这个范围是非对称的，这个非对称性的来源是0。对于补码来说，所有最高位为1的表示负数，所有最高位为0的表示非负数，因为0也被包含在最高位为0的所有二进制当中，所以有了这种左右区间的不对称性。</p>
<h3 id="为什么用补码表示有符号数"><a href="#为什么用补码表示有符号数" class="headerlink" title="为什么用补码表示有符号数"></a>为什么用补码表示有符号数</h3><p>首先补码只是有符号数的一种编码方式，当然如果你愿意的话也可以尝试开发有符号数的其他编码方式。补码被广泛地应用主要是因为其能提供很多好处：</p>
<ol>
<li>简化了了整数减法和负数加法的运算，在底层都可以用二进制的加法实现。这点之后会讲。</li>
<li>统一了有符号数和无符号数的运算在二进制层面的实现，使得两种数的四则运算<strong>几乎</strong>可以使用同一套规则。（唯一的例外是除法，之后会讲。）</li>
<li>符号位可以参与运算，同样下面会讲。</li>
</ol>
<p>另外我们知道非负数的补码就是其二进制表示，而负数的补码是其反码（除符号位逐位取反）加一。诚然对于一个负数，我们可以用上面的公式推导出其补码，但为什么补码和其原码有这样的关系呢？我们将在下面讲解。</p>
<p>值得一提的是，C语言的标准并没有规定有符号数要用补码实现，但事实上，几乎所有机器都是这么做的。Java语言则在标准中严格规定了有符号数必须用补码实现，当然Java中也并没有无符号数，也就是说Java中所有的整数都是用补码表示的。</p>
<h3 id="无符号数和有符号数的转换"><a href="#无符号数和有符号数的转换" class="headerlink" title="无符号数和有符号数的转换"></a>无符号数和有符号数的转换</h3><p>字长相同的有符号和无符号数之间的转换遵循一个标准：二进制的表示不变，解码的方式改变。比如对于32位全为1的二进制数，其对应的无符号十进制数为2<sup>32</sup> - 1 = 4294967295，有符号数的十进制为-1。</p>
<p>另外，在C语言当中，如果对有符号数和无符号数做某种运算操作（加法、减法等），有符号数会被隐式转换为无符号数，这样很容易造成一些bug。例如<code>-1 &lt; 0U</code>会被判定为<code>false</code>.</p>
<h3 id="位数的扩展与截断"><a href="#位数的扩展与截断" class="headerlink" title="位数的扩展与截断"></a>位数的扩展与截断</h3><p>当在字长不同的整数型数据当中进行转换的时候，不可避免地我们需要进行位的扩展和截断的操作。当把无符号数转化成更大的字长的数时，只需要在二进制前面加上一串零即可，这样不会改变无符号数的值。</p>
<p>对于有符号数，我们则是在前导加上对应的符号位。对于正数，和无符号数类似，其表示的值没有受到影响。对于负数，假设其原来为k位，扩展之后加了n位前导1，那么总共变成了n + k位：</p>
<ol>
<li>因为是负数，原来的k位补码，最高位肯定是1。假设剩下的k - 1位的和为C，那么其表示的十进制为-2<sup>k - 1</sup> + C。</li>
<li>当加了n位前导0时，从第0位到第k - 2位的和仍然是C。从第k - 1位到第n + k - 1位的和为-2<sup>n + k - 1</sup> + 2<sup>n + k - 2</sup> + … + 2<sup>k - 1</sup> = -2<sup>k - 1</sup>，那么加起来表示的数仍然为-2<sup>k - 1</sup> + C。</li>
</ol>
<p>我们讨论了在相同字长下，有符号数和无符号数之间的转化；以及，对应的无符号数和有符号数，在不同字长下的转化。那么如果同时进行了无符号数和有符号数，以及字长的转化，结果会是怎么样呢？我们考虑如下程序：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">short</span> sx = <span class="number">-12345</span>; <span class="comment">/* cf c7 */</span></span><br><span class="line"><span class="keyword">unsigned</span> uy = sx;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"uy = %u"</span>, uy);</span><br></pre></td></tr></table></figure>
<p>这个程序的输出结果为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">uy = <span class="number">4294954951</span> <span class="comment">/* ff ff cf c7 */</span></span><br></pre></td></tr></table></figure>
<p>在32位系统下，<code>short</code>为16位，<code>unsigned</code>为32位。看到最后的输出结果，我们可以看出来是先对<code>short</code>做了位数的扩展，之后进行了相同字长下有符号数到无符号数的转换。</p>
<p>我们可以看到，位数的扩展，在不同的数据类型中间会用到；位数的截断，同理也可以在整数的类型转换中用到，此外处理运算的溢出的时候也会用到。对于截断操作而言，其本质上就是在做模运算。假设从n位截断到k位（n &gt; k）：</p>
<ol>
<li>对于无符号数，截断后的值y = x mod 2<sup>k</sup>。</li>
<li>对于有符号数， 由于舍弃高位可能会导致符号改变，y = convertToSignedNum(x mod 2<sup>k</sup>)。</li>
</ol>
<h2 id="整数的运算"><a href="#整数的运算" class="headerlink" title="整数的运算"></a>整数的运算</h2><h3 id="加法和减法"><a href="#加法和减法" class="headerlink" title="加法和减法"></a>加法和减法</h3><p>无符号数加法没有什么特别，唯一需要注意的是溢出的情况，这种情况会按字长截断，也就是取模。所以字长为k位的两个无符号数x，y，其和x + y = (x + y) mod 2<sup>k</sup>。</p>
<p>有符号数是用补码表示的，非负数的加法和无符号数是类似的。但是涉及负数的话就不太一样了，因为负数的加法本质上就是减法，这个时候补码的好处就出现了。</p>
<p>首先对于字长固定的类型，在溢出位被截断的情况下，其模是固定的，假设为M。对于负数来讲<code>-x mod M = (M - x) mod M</code>，这个很好理解，对于一个时钟，向前拨十个刻度和向后拨十个刻度最后的结果是一样的，都是指向10。我们把M - x定义为x的补数，我们可以看到，-x和M - X对于M来讲是同余的。</p>
<p>因为这个性质，在我们做整数的减法时，可以转化为其补数的加法。例如对于两个字长固定的正整数x，y来说，<code>(x - y) mod M = (x + M - y) mod M</code>，因为补数加法同余的性质，我们截断（取余）溢出位之后，这两个结果在二进制非符号位上的表示是一样的。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x         15  0000 1111</span><br><span class="line">y         125 0111 1101</span><br><span class="line">M - y     3   0000 0011</span><br><span class="line">x + M - y 18  0001 0010</span><br></pre></td></tr></table></figure>
<p>加上符号位之后18 - 2<sup>7</sup> = 12 - 128 = -110 （1001 0010，正是对应减法的计算结果。如果我们直接把符号位带入<code>M - y</code>的话，对应的二进制就是<code>1000 0011</code>，是不是正好是-125的补码？同理：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x         125 0111 1101</span><br><span class="line">y         15  0000 1111</span><br><span class="line">M - y     113 0111 0001</span><br><span class="line">x + M - y 238 1110 1110</span><br></pre></td></tr></table></figure>
<p>由于最高位为符号位，溢出被截断，所以238 - 2<sup>7</sup> = 238 - 128 = 110 (0110 1110)，也是对应减法的计算结果。同理如果直接把符号位带入<code>M - y</code>，对应的二进制就是<code>1111 0001</code>，也是-15对应的补码。</p>
<p>我们可以看出来，直接把符号位带入的话，其二进制就是对应负数的补码，并且，符号位可以参与运算，不需要进行符号位的截断操作：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x     15   0000 1111</span><br><span class="line">-y    -125 1000 0011</span><br><span class="line">x - y -110 1001 0010</span><br><span class="line"></span><br><span class="line">x     125 0111 1101</span><br><span class="line">-y    -15 1111 0001</span><br><span class="line">x - y 110 0110 1110</span><br></pre></td></tr></table></figure>
<p>所以整数的减法可以在二进制层面用补码的加法实现，这样本质上整数的加法和减法，在二进制层面都变成了加法。这也就是为什么我们要用补码来表示符号数的原因。</p>
<p>另外值得一提的是，<code>M - y = (M - 1) - y + 1</code>，<code>(M - 1) - y</code>正好代表除了y的符号位全部取反，即反码；然后反码加一，变成了补码。</p>
<p>无符号数的减法也是类似的，那么显而易见地，在考虑溢出的情况下，k位无符号数和有符号数的加减法结果分别为（T<sub>k</sub>代表只截取最低k位，TC(x)表示x的补码）：</p>
<ul>
<li>无符号数<ul>
<li>x + y = T<sub>k</sub>(x + y)</li>
<li>x - y = T<sub>k</sub>(x + TC(Expanding(-y)))</li>
</ul>
</li>
<li>有符号数<br>  x ± y = T<sub>k</sub>(TC(x) + TC(±y))</li>
</ul>
<h3 id="检测溢出"><a href="#检测溢出" class="headerlink" title="检测溢出"></a>检测溢出</h3><p>对于无符号数x, y和其和s来说，当且仅当s &lt; x（此时y &lt; x也必为真），计算发生了溢出。<br>对于有符号数x，y和其和s来说：</p>
<ul>
<li>当且仅当x &gt; 0, y &gt; 0并且s &lt;= 0，计算发生正向溢出。</li>
<li>当且仅当x &lt; 0, y &lt; 0并且s &gt;= 0，计算发生负向溢出。</li>
</ul>
<p>证明不难，这里略过。</p>
<h3 id="乘法"><a href="#乘法" class="headerlink" title="乘法"></a>乘法</h3><p>乘法本质上还是加法，无符号数和有符号数的乘法在底层的运算逻辑还是一样的。对于k位的数，其乘法结果可能需要2k位才能表示，所以对于x和y来说，我们一般将其扩展到2k位，进行乘法运算，之后再截断。假设k为3：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unsinged:</span><br><span class="line"></span><br><span class="line">x 5 101</span><br><span class="line">y 3 011</span><br><span class="line"></span><br><span class="line">x * y = 000 101 * 000 011 = 001 111 = 15</span><br><span class="line">Truncated x * y = 111 = 7</span><br><span class="line"></span><br><span class="line">signed:</span><br><span class="line"></span><br><span class="line">x -3 101</span><br><span class="line">y 3  011</span><br><span class="line"></span><br><span class="line">x * y = 111 101 * 000 011 = 110 111 = -9</span><br><span class="line">Truncated x * y = 111 = -1</span><br></pre></td></tr></table></figure>
<p>因为整数乘法的运算更加耗时，一般会耗费10个或者更多的时钟周期，而相对的整数的加减法，位操作等只需要一个时钟周期。编译器会对变量乘以一个常量的计算进行优化，思路是转化为位操作和加法，这样处理之后生成的机器码，就只需要进行位操作和加法，时间比做乘法要快很多。</p>
<p>首先我们看乘以2的幂，这个大家都知道可以用位操作左移来实现。不管对于有符号是还是无符号数，x <em> 2<sup>k</sup>都可以等价为<code>x &lt;&lt; k</code>。那么对于任意常数C，因为其必定可以转化为2的幂的和，所以最后相乘的结果必定可以写出多个对x进行位操作左移的和。例如x </em> 14 = x * (2<sup>3</sup> + 2<sup>2</sup> +2<sup>1</sup>)，那么其可以表示为<code>(x &lt;&lt; 3) + (x &lt;&lt; 2) + (x &lt;&lt; 1)</code>。</p>
<p>同理14 = 2<sup>4</sup> - 2<sup>1</sup>，x * 14也可以表示为<code>(x &lt;&lt; 4) - (x &lt;&lt; 1)</code>。</p>
<p>所以对于x乘以任意常数C，其可以表示为一系列的1和0（括号里的全为0或者1）：</p>
<p><code>[(0...0)(1...1)(0...0)...(111)]</code></p>
<p>例如14就可以表示为<code>[(0...0)(111)(0)]</code>。对于一段连续的1，假设从第n位到第m位（n &gt;= m），我们可以将其表示为一下任意一种形式：</p>
<ol>
<li><code>(x &lt;&lt; n) + (x &lt;&lt; (n - 1) + ... + (x &lt;&lt; m))</code></li>
<li><code>(x &lt;&lt; (n + 1)) - (x &lt;&lt; m)</code></li>
</ol>
<h3 id="除法"><a href="#除法" class="headerlink" title="除法"></a>除法</h3><p>整数的除法比乘法还要慢，一般是30个时钟周期以上。但可惜的对于除以任意常量C，我们没有办法把其化为除以2的幂的和的形式，所以无法对其进行优化。但是对于除以2的幂的运算，我们还是可以用位操作进行优化。</p>
<p>因为可能无法整除的关系，我们首先定义整数的除法运算。对于任意实数a，我们首先定义⌊a⌋表示唯一的整数b使得b &lt;= a &lt; b + 1。例如⌊3.14⌋ = 3，⌊-3.14⌋ = -4。同理⌈a⌉表示唯一的整数b使得b - 1 &lt; a &lt;= b，例如⌈3.14⌉ = 4，⌈-3.14⌉ = -3。</p>
<p>那么对于任意整数x和y，当运算结果为正数时，结果应为⌊x / y⌋；而当结果为负数时，应为⌈x / y⌉。</p>
<p>那么这里有两种右移供我们选择，分别对应无符号数和有符号数的除法：</p>
<ol>
<li>逻辑右移：在最高位补1，这种用在无符号数的除法。</li>
<li>算数右移：在做高位补符号位，这种用在有符号数的除法。</li>
</ol>
<p>无论对于有符号数还是无符号数<code>x &gt;&gt; k</code>的结果都为⌊x / 2<sup>k</sup>⌋，所以对于结果为负的情况，我们要进行特殊处理:</p>
<p>当x &lt; 0时，对于k &gt;= 0, <code>(x + (1 &lt;&lt; k) - 1) &gt;&gt; k</code>的结果为⌈x / 2<sup>k</sup>⌉。</p>
<p>这个也不难理解，我们分两种情况讨论：</p>
<ol>
<li>当x正好能被2<sup>k</sup>整除，这后面加上的2<sup>k</sup> - 1在除以2<sup>k</sup>的时候会被舍去，所以结果为x / 2<sup>k</sup> = ⌈x / 2<sup>k</sup>⌉。</li>
<li>当x不能被2<sup>k</sup>整除时，x离⌈x / 2<sup>k</sup>⌉ * 2<sup>k</sup>的最大的差值就为2<sup>k</sup> - 1，所以加上之后再除就可以得到⌈x / 2<sup>k</sup>⌉。</li>
</ol>
<p>所以对于有符号数x除以2的幂的结果可以表示为：</p>
<p><code>(x &lt; 0? x + (1 &lt;&lt; k) - 1 : x) &gt;&gt; k</code></p>
]]></content>
      <categories>
        <category>Computer System</category>
        <category>Computing</category>
      </categories>
      <tags>
        <tag>Book Reading</tag>
        <tag>Computer System</tag>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title>Book Reading: Java Concurrency in Practice, Chapter 6</title>
    <url>/2021/05/03/book_reading_java_concurrency_6/</url>
    <content><![CDATA[<h2 id="Executing-tasks-in-threads"><a href="#Executing-tasks-in-threads" class="headerlink" title="Executing tasks in threads"></a>Executing tasks in threads</h2><p>The first step in organizing a program around task execution is identifying sensible <em>task boundaries</em>. Ideally, tasks are <em>independent</em> activities: work that doesn’t depend on the state, result, or side effects of other tasks. Independence facilitates concurrency, as independent tasks can be executed in parallel if there are adequate processing resources.<br><a id="more"></a><br>Server applications should exhibit both <em>good throughput</em> and <em>good responsiveness</em> under normal load. Further, applications should exhibit <em>graceful degradation</em> as they become overload, rather than simply falling over under heavy load. Choosing good task boundaries, coupled with a sensible <em>task execution policy</em>, can help achieve these goals.</p>
<p>Most server applications offer a natrual choice of task boundary, individual client requests. Using individual requests as task boundaries usually offers both independence and approriate task sizing.</p>
<p>There are number of possible policies for scheduling tasks within an application, some of which explit the potential for concurrency better than others. The simplest is to execute tasks sequentially in a single thread. But processing a web request involves a mixed of computation and I/O. The server must perform socket I/O to read the request and write the response, which can block due to network congestion or connectivity problems. It may also perform file I/O or make database requests, which can also block. In a single-threaded server, blocking not only delays completing the current request, but prevents pending requests from being processed at all.</p>
<p>A more responsive approach is to create a new thread for servicing each request, in this way, for each connection, the main loop creates a new thread to process the request instead of processing it within the main thread. This has some main consequences:</p>
<ul>
<li><p>Task processing is offloaded from the main thread, enabling the main loop to resume waiting for the next incoming connection more quickly. This enables new connections to be accepted before previous requests complete, improving responsiveness.</p>
</li>
<li><p>Tasks can be processed in parallel, enabling multiple requests to be serviced simultaneously. This may improve throughput if there are multiple processors, or if tasks need to block for any reason such as I/O completion, lock acquisition, or resource availability.</p>
</li>
</ul>
<p>For production use, however, the thread-per-task approach has some practical drawbacks, especially when a large number of threads may be created:</p>
<p><strong>Thread lifecycle overhead.</strong> Thread creation and teardown are not free. The actual overhead varies across platform, but thread creation takes time, introducing latency into request processing, and requires some processing activity by the JVM and OS, If requests are frequent and lightweight, as in most server applications, creating a new thread for each request can consume significant computing resources.</p>
<p><strong>Resource consumption.</strong> Active threads consume system resources, especially memory. When there are more runnable threads than available processors, threads sit idle. Having many idel threads can tie up a lot of memory, putting pressure on the garbage collector, and having many threads competing for the CPUs can impose other performance cost as well.</p>
<p><strong>Stability.</strong> There is a limit on how many threads can be created. The limit varies by platform and is affected by factors including JVM invocation parameters, the requestd stack size in the <code>Thread</code> constructor, and limits on threads placed by the underlying operation system.</p>
<p>Up to a certain point, more threads can improve throughput, but beyond that point creating more threads just slows down your application, and creating one thread too many can cause your entire application to crash horribly.</p>
<h2 id="The-Executor-framework"><a href="#The-Executor-framework" class="headerlink" title="The Executor framework"></a>The <code>Executor</code> framework</h2><p>In <a href="https://kanrourou.github.io/2021/04/30/book_reading_java_concurrency_5/" target="_blank" rel="noopener">Chapter 5</a>, we saw how to use <em>bounded queues</em> to prevent an overloaded appplication from running out of memory. <em>Thread pools</em> offer the same benefit for thread mangedment, and <code>java.util.concurrent</code> provides a flexible thread pool implementation as part of the <code>Executor</code> framework.</p>
<p><code>Executor</code> provides a standard means of decoupling <em>task submission</em> from <em>task exectution</em>. It is based on the producer-consumer pattern, where activities that submit tasks are the producers and the threads that execute tasks are the consumers. Using a <code>Executor</code> is <em>usually the easiest path to implementing a producer-consumer design in your application</em>.</p>
<p>The value of decoupling submission from execution is that it lets you easiliy specify, and subsequently change without great difficulty the <em>execution policy</em> for a given class of tasks. An execution policy specifies the “what, where, when, and how” of task exectution, including:</p>
<ul>
<li>In what thread will tasks be executed?</li>
<li>In what order should tasks be executed (FIFO, LIFO, priority order)?</li>
<li>How many tasks may execute concurrently?</li>
<li>How many tasks may be queued pending execution?</li>
<li>If a task has to be rejected because the system is overloaded, which task should be selected as the victim, and how should the application be notified?</li>
<li>What actions should be taken before or after executing a task?</li>
</ul>
<p>Execution policies are a resource management tool, and the optimal policy depends on the available computing resources and your quality-of-service requiremnts. Separating the specification of execution policy from task submission makes it practical to select an execution policy at depolyment time that is matched to the available hardware.</p>
<p>A thread pool, as its name suggests, manages a homogeneous pool of worker threads. A thread pool is tightly bound to a <em>work queue</em> holding tasks waiting to be executed.</p>
<p>Executing tasks in pool threads has a number of advantages over the thread-per-approach, Reusing an existing thread instead of creating a new one amortizes thread creation and teardown costs over multiple requests. As an added bonus, since the worker thread often already exists at the time the request arrives, the latency associated with thread creation does not delay task execution, thus improve responsiveness. By properly tuning the size of the thread pool, you can have enough threads to keep the processors busy while not having so many that your application runs out of memory or thrashes due to competition among threads for resources.</p>
<p>The class library provides a flexible thread pool implementation along with some useful predefined configurations:</p>
<p><strong>newFixedThreadPool.</strong> A fixed-size thread pool creates threads as tasks are submitted, up to the maximum pool size, and then attempts to keep the pol size constant.</p>
<p><strong>newCachedThreadPool.</strong> A cached thread pool has more flexibility to reap idle threads when the current size of the pool exceeds the demand for processing, and to add new threads when demand increases, but places no bounds on the size of the pool.</p>
<p><strong>newSingleThreadExecutor.</strong> A single-threaded executor creates a single worker thread to process tasks, replacing it if it dies unexpectedly. Tasks are guaranteed to be processed sequentially according to the order imposed by the task queue (FIFO, LIFO, priority order).</p>
<p><strong>newScheduledThreadPool.</strong> A fixed-size thread pool that supports delayed and periodic task execution, similar to <code>Timer</code>.</p>
<p>Since the JVM can’t exit until all the (nondaemon) threads have terminated, failling to shut down an <code>Executor</code> could prevent the JVM from exiting. In shutting down an application, there is a spectrum from graceful shutdown to abrupt shutdown, and various points in between. Since <code>Executors</code> provide a service to applications, they should be able to able to shut down as well, both gracefully and abruptly, and feed back information to the application about the status of tasks that were affected by the shutdown.</p>
<p>To address the issue of execution service lifecycle, the <code>ExecutorService</code> interface extends <code>Executor</code>, adding a number of methods for lifecycle management:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ExecutorService</span> <span class="keyword">extends</span> <span class="title">Executor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">List&lt;Runnable&gt; <span class="title">shutdownNow</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isShutdown</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isTerminated</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">awaitTermination</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The lifecycle implited by <code>ExecutorService</code> has three states–<em>running, shutting down,</em> and <em>terminated</em>. The <code>shutdown</code> method initiates a graceful shutdown: no new tasks are accepted but previously submitted tasks are allowed to complete–including those that have not begun execution. The <code>shutdownNow</code> method initiates an abrupt shutdown: it attempts to cancel outstanding tasks and does not start any tasks that are queued but not begun. Once all tasks have completed, the <code>ExecutorService</code> transitions to the <em>terminated</em> state. You can wait for an <code>ExecutorService</code> to reach the terminated state with <code>awaitTermination</code>, or poll for whether it has yet terminated with <code>isTerminated</code>.</p>
<p>The <code>Timer</code> facility manages the execution of deferred and periodic tasks. However, <code>Timer</code> has some drawbacks, and <code>ScheduledThreadPoolExecutor</code> should be thought of as its replacement.</p>
<p>A <code>Timer</code> creates only a single thread for executing timer tasks. If a timer task takes too long to run, the timing accuracy of other <code>TimerTasks</code> can suffer. Another problem with <code>Timer</code> is that it behaves poorly if a <code>TimerTask</code> throws an unchecked exception. The <code>Timer</code> thread doesn’t catch the exception, so an unchecked exception thrown from a <code>TimerTask</code> terminates the timer thread. <code>Timer</code> also doesn’t resurrect the thread in this situation; instead, it erroneously assumes the entire <code>Timer</code> was cancelled. In this case, <code>TimerTasks</code> that are already scheduled but not yet executed are never run, and new tasks cannot be scheduled.</p>
<p>If you need to build your own scheduling service, you may still be able to take advantage of the library by using a <code>DelayQueue</code>, a <code>BlockingQueue</code> implementation that provides the scheduling functionality of <code>ScheduledThreadPoolExecutor</code>. A <code>DelayQueue</code> manages a collection of <code>Delayed</code> objects. A <code>Delayed</code> has a delay time associate with it: <code>DelayQueue</code> lets you take an element only if its delay has expired. Objects are returned from a <code>DelayQueue</code> ordered by the time associated with their delay.</p>
<h2 id="Finding-exploitable-parallelism"><a href="#Finding-exploitable-parallelism" class="headerlink" title="Finding exploitable parallelism"></a>Finding exploitable parallelism</h2><p>In most server application, there is an obvious task boundary: a single client request. But sometimes good task boundaries are not quite so obvious. In this ection we develop several versions of a component that admit varying degree of concurrency. Our sample component is the page-rendering portion of a browser application, which takes a page of HTML and renders it into an image buffer.</p>
<p>The simplest approach is to process the HTML document sequentially, but is likely to annoy the user, who may have to wait a long time before all the text is rendered.</p>
<p>A less annoying but still sequential approach involves rendering the text elements first, leaving rectangular placeholders for the images, and after completing the initial pass on the document, going back and downloading the images and drawing them into the associated placeholder.</p>
<p>Downloading an image mostly involves waiting for I/O to complete, and during this time the CPU does little work. So the sequential approach may under-utilize the CPU, and also makes the user wait longer than necessary to see the finished page. We can achieve better utilization and responsiveness by breaking the problem into independent tasks that can execute concurrently.</p>
<p>The <code>Executor</code> framework uses <code>Runnable</code> as its basic task representation. <code>Runnable</code> is a fairly limiting abstraction, and has following differences <code>Callable</code>:</p>
<ul>
<li><code>Callable</code> can return a value but <code>Runnable</code> can’t.</li>
<li><code>Callable</code> can throw checked exception so the caller method can catch and handle; while the <code>Runnable</code> can’t throw and all exceptions need to be handled in <code>run</code> method.</li>
<li><code>Executor.execute</code> method only takes <code>Runnable</code> and <code>Executor.submit</code> takes both <code>Runnable</code> and <code>Callable</code>, a <code>Future</code> is returned by calling <code>submit</code>, but the <code>Runnable</code> one won’t contain any value.</li>
</ul>
<p>The lifecycle of a task executed by an <code>Executor</code> has four phases: <em>created, submitted, started,</em> and <em>completed</em>. Since tasks can take a long time to run, we also want to be able to cancel a task. In the <code>Executor</code> framework, tasks that have been submitted but not yet started can always be cancelled, and tasks that have started can sometimes be cancelled if they are responsive to interruption.</p>
<p>There are several ways to create a <code>Future</code> to describe a task. The <code>submit</code> methods in <code>ExecutorService</code> all return a <code>Future</code>, so that you can submit a <code>Runnable</code> or a <code>Callable</code> to an executor and get back a <code>Future</code> that can be used to retrieve the result or cancel the task. </p>
<p>Submitting a <code>Runnable</code> or <code>Callable</code> to an <code>Executor</code> consititutes a safe publicatoin of the <code>Runnable</code> or <code>Callable</code> from the submitting thread to the thread that will eventually execute the task. Similarly, setting the result value for a <code>Future</code> consititues a safe publication of the result from the thread in which it was computed to any thread that retrieves it via <code>get</code>.</p>
<p>As a first step towards making the page renderer more concurrent, let’s divide it into two tasks, one that renders the text and one that downloads all the images. So we can create a <code>Callable</code> to download all the images, and submit it to an <code>ExecutorService</code>. This returns a <code>Future</code> describing the task’s execution; when the main task gets to the point where it needs the images, iw waits for the result by calling <code>Future.get</code>. This allows the text to be rendered concurrently with downloading the image data. But there is no need for user to wait for all the images to be downloaded; they would probably prefer to see individual images drawn as they become available.</p>
<p>Parallelizing sequential heterogeneous tasks can significant improving performance, however, assigning a different type of task to each worker does not scale well. Without finding finer-grained parallelism among similar tasks, this approach will yield diminishing returns. A further problem with dividing heterogeneous tasks among multiple workers is that the tasks may have disparate sizes. Thus, trying to increase concurrency by paralleizing heterogeneous activities can be a lot of work, and there is a limit to how much additional concurrency you can get out of it.</p>
<p>If you have a batch of computations to submit to an <code>Executor</code> and you want to retrieve their results as the become available, you could retain the <code>Future</code> associated with each task and repeatedly poll for completion by calling <code>get</code> with a timeout of zero. This is possible, but tedious. Fortunately there is a better way: a <em>completion service</em>.</p>
<p><code>CompletionService</code> combines the functionality of an <code>Executor</code> and a <code>BlockingQueue</code>, You can submit <code>Callable</code> tasks to it for execution and use the queue like methods <code>take</code> and <code>poll</code> to retrieve completed results, packaged as <code>Futures</code>, as they become available. Bascially, individual can think of <code>Executor</code> as something like input queue + thread pool and <code>CompletionService</code> as input queue + thread pool + output queue.</p>
<p>And we can use <code>CompletionService</code> to shorter total runtime and improve responsiveness for the page render. We can create a separate task for downloading each image and execute them in a thread pool, turning the sequential download into a parallel one: this reduces the amount of time to download all the images. And by fetching results from the <code>CompletionService</code> and rendering each image as soon as it is available, we can give the user a more dynamic and responsive user interface.</p>
<p>Sometimes, if an activity does not complete within a certain amount of time, the results is no longer needed and the activity can be abandoned. The timed version of <code>Future.get</code> supports this requirement: it returns as soon as the result is ready, but throws <code>TimeoutException</code> if the result is not ready within the timeout period.</p>
<p>When timed tasks run out of time, we may want to stop them so the do not waste computing resources by continuing to compute a result that will not be used. Again, <code>Future</code> can help; if a timed <code>get</code> completes with a <code>TimedoutException</code>, you can cancel the task through the <code>Future</code>. If the task is written to be cancellable, it can be terminated early so as not to consume excessive resources.</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
        <tag>Book Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>Book Reading: Java Concurrency in Practice, Chapter 5</title>
    <url>/2021/04/30/book_reading_java_concurrency_5/</url>
    <content><![CDATA[<h2 id="Synchronized-collections"><a href="#Synchronized-collections" class="headerlink" title="Synchronized collections"></a>Synchronized collections</h2><p>The synchronized collection classes include <code>Vector</code> and <code>Hashtable</code>, which achieve thread safety by encapsulating their state and synchronizing every public method so that only one thread at a time can access the collection state,<br><a id="more"></a></p>
<p>The synchronized collections are thread-safe, but you may sometimes need to use additional client-side locking to guard compound actions. Common compound actions on collection include iteration, navigation, and conditional operations such as put-if-absent.</p>
<p>Because the synchronized collections commit to a synchronization policy that supports client-side locking, it is possible to create new operations that are atomic with respect to other collection operations as long as we know which lock to use. The synchronized collection classes guard each method with the lock on the synchronized collection object itself.</p>
<p>The iterators returned by the synchronized collections are not designed to deal with concurrent modification, and they are fail-fast–meaning that if they detect that collection has changed since iteration began, they throw the unchecked <code>ConcurrentModificationException</code>. Note that the <code>ConcurrentModificationException</code> can arise in single-threaded code as well; this happens when objects are removed from the collection directly rather than through <code>Iterator.remove</code>.</p>
<p>There are several reasons, however, why locking a collection during iteration may be undesirable. Other threads that need to access the collection will block until the iteration is complete. An alternative to locking the collection during iteration is to clone the collection and iterate the copy instead. Cloning the collection has an obvious performance cost; whether this is a favorable tradeoff depends on many factors including the size of the collection, work for each element, etc.</p>
<p>While locking can prevent iterators from throwing <code>ConcurrentModificationException</code>, you have to remember to use locking everywhere a shared collection might be iterated. For example, calling a <code>toString</code>, <code>hashCode</code> or <code>equals</code> methods on a collection can result in underlying call of the iterator. All of these indirect uses of iteration can cause <code>ConcurrentModificationException</code>.</p>
<h2 id="Concurrent-collections"><a href="#Concurrent-collections" class="headerlink" title="Concurrent collections"></a>Concurrent collections</h2><p>Synchronized collections achieve their thread safety by serializing all access to the collection’s state. The cost of this approach is poor concurrency; when multiple threads contend for the collection-wide lock, throughtput suffers. The concurrent collections, on the other hand, are designed for concurrent access from multiple threads.</p>
<h3 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h3><p><code>ConcurrentHashMap</code> is a hash-based <code>Map</code> like <code>HashMap</code>, but it uses an entirely different locking strategy that offers better concurrency and scalability. Instead of synchronizing every method on a common lock, restricting access to a single thread at a time, it uses a finer-grained locking mechanism called <code>lock striping</code> to allow a greater degree of shared access. Arbitrarily many reading threads can access the map concurrently, readers can access the map concurrently with writers, and a limited number of writers can modify the map concurrently. The result is far higher throughtput under concurrent access, with little performance penalty for single-threaded access.</p>
<p><code>ConcurrentHashMap</code> further improve on synchronized collection classes by providing iterators that do not throw <code>ConcurrentModificationException</code>, thus eliminating the need to lock the collection during iteration. The iterators returned by <code>ConcurrentHashMap</code> are <code>weakly consistent</code> instead of fail-fast. A weakly consistent iterator can tolerate concurrent modification, traverse elements as tehy existed when the iterator was constructed, and may (but is not guaranteed to) reflect modification to the collection after the construction of the iterator.</p>
<p>The semantics of methods that operate on the entire <code>Map</code>, sunch as <code>size</code> and <code>isEmpty</code>, have been slightly weakened to reflect the concurrent nature of the collection. Since the result of <code>size</code> could be out of date by the time it is computed, it is really only an estimate, so <code>size</code> is allowed to return an approximation instead of an exact count. While at first this may seem disturbing, in reality methods like <code>size</code> and <code>isEmpty</code> are far less useful in concurrent environments because these quantities are moving targets. So the requirements for these operations were weakened to enable performance optimizations for the most important operations, primarily <code>get</code>, <code>put</code>, <code>containsKey</code> and <code>remove</code>.</p>
<h3 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h3><p><code>CopyOnWriteArrayList</code> is a concurrent replacement for a synchronized <code>List</code> that offers better concurrency in some common situations and eliminates the need to lock or copy the collection during iteration.</p>
<p>The copy-on-write collections derive their thread safety from the fact that as long as an effective immutable object is properly published, no further synchronization is required when accessing it. They implement mutability by creating and republishing a new copy of the collection every time it is modified. Iterators for the copy-on-write collections retain a reference to the backing array that was current at the start of iteration, and since this will never change, they need to synchronize only breifly to ensure visibility of the array contents. As a result, multiple threads can iterate the collection without interference from on another or from threads wanting to modify the collection. The iterator returned by the copy-on-write colletions return the elements exactly as they were at the time the iterator was created, regardless of subsequent modifications.</p>
<p>The copy-on-write collections are reasonable to use only when iteration is far more common than modification. This criterion exactly describes many event-notification systems: delivering a notification requires iterating the list of registered listeners and calling each one of them, and in most cases registering or unregistering an event listener is far less common than receiving an event notification.</p>
<h2 id="Blocking-queues-and-the-producer-consumer-pattern"><a href="#Blocking-queues-and-the-producer-consumer-pattern" class="headerlink" title="Blocking queues and the producer-consumer pattern"></a>Blocking queues and the producer-consumer pattern</h2><p>Blocking queues provide blocking <code>put</code> and <code>take</code> methods as well as the timed equivalents <code>offer</code> and <code>poll</code>. If the queue is full, <code>put</code> blocks until space becomes available; if the queue is empty, <code>take</code> blocks until an element is available.</p>
<p>Blocking queues support the <em>producer-consumer</em> design pattern. This pattern simplifies development because it removes code dependencies between producer and consumer classes, and simplifies workload management by decoupling activities that may produce or consume data at different or variable rates.</p>
<p>If the producers consistently generate work faster than the consumers can process it, eventually the application will run out of memory because work items will queue up without bound. Again, the blocking nature of <code>put</code> greatly simplfies coding of producers; if we use a bounded queue, then when the queue fills up the producer block, giving the consumers time to catch up because a blocked producer cannot generate more work.</p>
<p>Blocking queues also provide an <code>offer</code> method, which returns a failure status if the item cannot be enquered. This enables you to create more flexiable policies for dealing with overload, such as shedding load, serialzing excess work items and writing them to disk, reducing the number of producer threads, or throttling producers in some other manner.</p>
<p>The class library contains several implementation of <code>BlockingQueue</code>. <code>LinkedBlockingQueue</code> and <code>ArrayBlockingQueue</code> are FIFO queues, <code>PriorityBlockingQueue</code> is a priority-ordered queue. <code>SynchronousQueue</code>, is not really a queue at all, in that it maintains no storage space for queued elements. Instead, it maintains a list of queued threads waiting to enqueue or dequeue an element. It reduces the latency associated with moving data from producer to consumer because the work can be handed off directly. The direct handoff also feeds back more information about the state of the task to the producer. Since <code>SynchronousQueue</code> has not storage capacity, <code>put</code> and <code>take</code> will block unless another thread is already waiting to participate in the handoff. <code>SynchronousQueue</code> is generally suitable only when there are enough consumers that there nearly always will be one ready to take the handoff.</p>
<p>The blocking queue implementations in <code>java.util.concurrent</code> all contain sufficient internal synchrnization to safely publish objects from a producer thread to the consumer thread. For mutable objects, producer-cosumer designs and blocking queues facilitates <em>serial thread confinement</em> for handling off ownership of objects from producers to consumers. A thread-confined object is owned exclusively by a single thread, but that ownership can be “transferred” by publishing it safely where only one other thread will gain access to it and ensuring that the publishing thread does not access it after the handoff. The safe publication ensures that the object’s state is visible to the new owner, and since the original owner will not touch it again, it is now confied to the new thread. The new owner may modify it freely since it has excludive access.</p>
<p>A <code>Deque</code> is a double-ended queue that allows efficient insertion and removal from both the head and the tail. Deques lend themselves to a related pattern called <em>work stealing</em>. In a work stealing design, every consumer has its own deque. If a consumer exhausts the work in its own deque, it can steal work from the tail of someone else’s deque. Work stealing can be more scalable than a traditional producer-consumer design because workers don’t contend for a shared work queue; most of the time they access only their own deque, reducing contention. When a worker has to access another’s deque, it does so from the tail rather than the head, further reducing contention. Working stealing is well suited to problem in which consumers are also producers–when performing a unit of work is likely to result in the identification of more work (e.g. processing a page in web crawler can result in new pages to be crawled). When a worker identifies a new unit of work, it places it at the end of its own deque; when its deque is empty, it looks for work at the end of someone else’s deque, ensuring that each worker stays busy.</p>
<h2 id="Blocking-and-interruptible-methods"><a href="#Blocking-and-interruptible-methods" class="headerlink" title="Blocking and interruptible methods"></a>Blocking and interruptible methods</h2><p>Threads may block, or pause, for several reasons: wainting for I/O completion, waiting to acquire a lock, waiting to wake up from <code>Thread.sleep</code>, or waiting for the result of a computation in another thread. When a thread blocks, it is usually suspended and placed in one of the blocked thread states (<code>BLCOKED</code>, <code>WAITING</code>, or <code>TIMED_WAITING</code>). The distinction between a blocking operation and an ordinary operation that merely takes a long time to finish is that a blocked thread must wait for an event that is beyong its control before it can proceed–the I/O completes, the lock becomes available, or the external computation finishes.</p>
<p>When a method can throw <code>InterruptedException</code>, it is telling you that is is a blocking method, and further that if it is interrupted, it will make an effort to stop blocking early.</p>
<p><code>Thread</code> provides the <code>interrupt</code> method for interrupting a thread and for querying whether a thread has been interrupted. Each thread has a boolean property that represents its interrupted status; interrupting a thread sets this status.</p>
<p>Interruption is a cooperative mechanism. One thread cannot force another to stop what it is doing and do something else; when thread A interrupts thread B, A is merely requesting that B stop what it is doing when it gets to a convenient stopping point. The most sensible use for interruption is to cancel an activity. Blocking methods that are responsive to interruption make it easier to cancel loing-running activities on a timely basis.</p>
<h2 id="Synchronizers"><a href="#Synchronizers" class="headerlink" title="Synchronizers"></a>Synchronizers</h2><p>A <em>synchronizer</em> is any object that coordinates the control flow of threads based on its state. Blocking queues can act as synchronizers; other types of synchronizers include semaphores, barriers and latches.</p>
<p>All synchronizers share certain structural properties: they encapsulate state that determines whether threads arriving at the synchronizer should be allowed to pass or forced to wait, provide methods to manipulate that state, and provide methods to wait efficiently for the synchronizer to enter the desired state.</p>
<h3 id="Latches"><a href="#Latches" class="headerlink" title="Latches"></a>Latches</h3><p>A <em>latch</em> is a synchronizer that can delay the progress of threads until it reaches its <em>terminal</em> state. A latch acts as a gate: until the latch reaches the terminal state the gate is closed and no thread can pass, and in the terminal state the gate opens, allowing all threads to pass. Once the latch reaches the terminal state, it cannot change state again, so it remains open forever. Latches can be used to ensure that certain activites do not proceed until other one-time activities complete, such as:</p>
<ul>
<li>Ensuring that a computation does not proceed until resources it needs have been initialized.</li>
<li>Ensureing that a service does not start until other services on which it depends have started.</li>
<li>Waiting until all the parties involved in an activity, for instance the players in a multi-player game, are ready to proceed.</li>
</ul>
<p><code>CountDownLatch</code> is a flexible latch implementation that can be used in any of these situations; it allows one or more threads to wait for a set of events to occur. The latch state consists of a counter initialized to a positive number, representing number of events to wait for. The <code>countDown</code> method decrements the counter, indicating that an event has occuered, and the <code>await</code> methods wait for the counter to reach zero. If the counter is nonzero on entry, <code>await</code> blocks until the counter reaches zero, the waiting thread is interrupted, or the wait times out.</p>
<h3 id="FutureTask"><a href="#FutureTask" class="headerlink" title="FutureTask"></a>FutureTask</h3><p><code>FutureTask</code> also acts like a latch. (<code>FutureTask</code> implements <code>Future</code>, which describes an abstract result-bearing computation.) A computation represented by a <code>FutureTask</code> is implemented with a <code>Callable</code>, the result-bearing equivalent of <code>Runnable</code>, and can be in one of three states: waiting to run, running, or completed. Completion subsumes all the ways a computation can complete, including normal completion, cancellation, and exception. Once a <code>FutureTask</code> enters the completed state, it stays in that state forever.</p>
<p>The behavior of <code>Future.get</code> depends on the state of the task. If it is completed, get returns the result immediately, and otherwise blocks until the task transitions to the completed state and then returns the result or throws an exception. <code>FutureTask</code> conveys the result from the thread executing the computation to the thread retrieving the result; the specification of <code>FutureTask</code> guarantee that this transfer constitutes a safe publication of the result.</p>
<p><code>FutureTask</code> is used by the <code>Executor</code> framework to represent asynchronous tasks, and can also be used to represent any potentially lengthy computation that can be started before the results are needed.</p>
<h3 id="Semaphores"><a href="#Semaphores" class="headerlink" title="Semaphores"></a>Semaphores</h3><p><em>Counting semaphores</em> are used to control the number of activities that can access a certain resource or perfrom a given action at the same time. Counting semaphore can be used to impplement resource pools or to impose a bound on a collection.</p>
<p>A <code>Semaphore</code> manages a set of vertual <em>permits</em>; the initial number of permits is passed to the <code>Semaphore</code> constructor. Activities can acquire permits and release permits when they are done with them. If no permit is available, <code>acquire</code> blocks until one is (or until interuptted or the operation times out). The <code>release</code> method returns a permit to the semaphore. A degenerate case of a counting semaphore is a binary semaphore, a binary semaphore can be used as a <em>mutex</em> with nonreentrant locking semantics; whoever holds the sole permit holds the mutext.</p>
<p>Semaphores are useful for implementing resource pools sunch as database connection pools. While it is easy to construct a fixed-sized pool that fails if you request a resource from an empty pool, what you really want is to block if the pool is empty and unblock when it becomes nonempty again. Similarly, you can use a <code>Semaphore</code> to turn any collection into a blocking bounded collection.</p>
<h3 id="Barries"><a href="#Barries" class="headerlink" title="Barries"></a>Barries</h3><p><em>Barriers</em> are similar to latches in that they block a group of threads until some event has occurred. The key difference is that with a barrier, all the threads must come together at a barrier point <em>at the same time</em> in order to proceed. Latches are for waiting for <em>events</em>; barriers are for waiting for <em>other threads</em>. </p>
<p><code>CyclicBarrier</code> allows a fixed number of parties to rendezvous repeatedly at a <em>barrier point</em> and is useful in parallel iterative algotithms that break down a problem into a fixed number of independent subproblems. Threads call <code>await</code> when they reach the barrier point. If all threads meet at the barrier point, the barrier has been successfully passed. If a call to <code>await</code> times out or a thread blocked in <code>await</code> is interrupted, then the barrier is considered broken and all outstanding calls to <code>await</code> terminate with <code>BrokenBarrierException</code>. If the barrier successfully passed, <code>await</code> returns a unique arrival index for each thread, which can be used to “elect” a leader that takes some special action in the next iteration.</p>
<p>Barriers are often used in simulations, where the work to calculate one step can be done in parallel but all work associated with a given step must complete before advancing to the next step. Another form of barrier is <code>Exchanger</code>, a two-party barrier in which the parties exchange data at the barrier point.</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
        <tag>Book Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>Book Reading: Java Concurrency in Practice, Chapter 13</title>
    <url>/2021/02/07/book_reading_java_concurrency_13/</url>
    <content><![CDATA[<h2 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h2><p>The <code>Lock</code> interface in Java offers a choice of unconidtional, polled, timed, and interruptible lock acquisition, and all lock and unlock operations are explicit. <code>ReentrantLock</code> implements <code>Lock</code>, providing the same mutual exclusion and memory-visibility gurantees as <code>synchronized</code>. Acquiring a <code>ReentrantLock</code> has the same memory semantics as entering a <code>synchronized</code> block, and releasing a <code>ReentrantLock</code> has the same memory semantics as exiting a <code>synchronized</code> block.<br><a id="more"></a></p>
<p>Why create a locking mechanism that is so similar to intrinsic locking? Intrinsic locking works fine in most cases but has some functional limitations, for example:</p>
<ul>
<li>It is not possible to interrupt a thread waiting to acquire a lock, or to attempt to acquire a lock without being willing to wait for it forever.</li>
<li>It must be released in the same block of code in which they are acquired.</li>
</ul>
<p>A canonical form for using a <code>Lock</code> is as below:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Lock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">lock.lock();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// Do something...</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    lock.unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Note the lock <em>must</em> be released in a <code>finally</code> block, otherwise it will never be released if the guarded code were to throw a exception. So it is more dangerous than intrinsic lock because it doesn’t automatically clean up the lock when control leaves the guarded block.</p>
<h3 id="Polled-and-timed-lock-acquistion"><a href="#Polled-and-timed-lock-acquistion" class="headerlink" title="Polled and timed lock acquistion"></a>Polled and timed lock acquistion</h3><p>The timed and polled lock-acquisition modes provided by <code>tryLock</code> allow more sophisticated error recovery than unconditional acquisition. Using it lets yout regain control if you cannot acquire all the required locks, release the ones you did acquire, and try again or at least log the failure and do something else. Example:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">transferMoney</span><span class="params">(Account fromAcct, Account toAcct, DollarAmount amount, <span class="keyword">long</span> timeout, TimeUnit unit)</span> <span class="keyword">throws</span> InsufficientFundsException, InterruptException </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> fixedDelay = getFixedDelayComponentsNanos(timeout, unit);</span><br><span class="line">    <span class="keyword">long</span> randMod = getRandomDelayModNanos(timeout, unit);</span><br><span class="line">    <span class="keyword">long</span> stopTime = System.nanoTime() + unit.toNanos(timeout);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (fromAcct.lock.tryLock()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (toAcct.lock.tryLock()) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="keyword">if</span> (fromaAcct,getBalance().compareTo(amount) &lt; <span class="number">0</span>)</span><br><span class="line">                            <span class="keyword">throw</span> <span class="keyword">new</span> InsufficientFundsException();</span><br><span class="line">                        <span class="keyword">else</span> &#123;</span><br><span class="line">                            fromAcct.debit(amount);</span><br><span class="line">                            toAcct.credt(amount);</span><br><span class="line">                            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                        toAcct.lock.unlock();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                fromAcct.lock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (System.nanoTime() &gt; stopTime)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span></span><br><span class="line">        NANOSECONDS.sleep(fixedDelay + rnd.nextLong() % randMod);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The program uses <code>tryLock</code> to attempt both locks, but back off and retry if they cannot both be acquired. Note this try-wait-acquire pattern can result in livelock problem, which is a risk with some algorithm that detect and recover from deadlock. If more than one processes take action, the deadlock detection algorithm can be repeatly triggered. The states of processes involved in the livelock constantly change with regard to one another, no progress will be made. Livelock is similar to deadlock, the most important difference is that the threads are not blocked, instead they will try to respond to each other continuously. So in this example, it is possible that several threads are trying to acquire the lock at the same time and all back offs, that is why we need to add a random component to reduce the likelihood of livelock.</p>
<p>Timed locks are also useful in implementing activities that manage a time budget. This lets activities terminate early if they cannot deliver a result within the desired time. With intrinsic locks, there is no way to cancel a lock acquisition once it is started.</p>
<h3 id="Interruptible-lock-acquisition"><a href="#Interruptible-lock-acquisition" class="headerlink" title="Interruptible lock acquisition"></a>Interruptible lock acquisition</h3><p>The interruptible lock acquistion allows locking to be used within cancellable activities. The <code>lockInterruptibly</code> method allows you to try to acquire a lock while remaining responsive to interruption. An example of usage:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">lockInterruptiblyExample</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    lock.lockInterruptibly();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Do something...</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The usage is pretty similar with <code>lock()</code>, the key differences are:</p>
<ol>
<li>If the current thread is already interrupted when calling <code>lockInterruptibly</code>, it won’t acquire the lock, and throws <code>InterruptedException</code>.</li>
<li>If the current thread is interrupted when acquiring the lock, it won’t acquire the lock, and throws <code>InterruptedException</code>.</li>
</ol>
<p>Note this is different when interrupting a thread that already acquired the lock, you need to handle the lock releasing logic carefully since it is currently held by the thread.</p>
<h3 id="Fairness"><a href="#Fairness" class="headerlink" title="Fairness"></a>Fairness</h3><p>The <code>ReentrantLock</code> constructor offers choice of two <em>faireness</em> options: create a <em>non-fair</em> lock (the default) or a <em>fair</em> lock. The differnces are:</p>
<ol>
<li>Threads acquire a fair lock in the order in which they requested it.</li>
<li>A nonfair lock permits barging: threads requesting a lock can jump ahead of the queue of waiting threads if the lock happens to be available when it is requested.</li>
</ol>
<p>When it comes to locking, fairness has significant performance cost because of the overhead of suspending and resuming threads. In practice, a statistical fairness guarantee–promising that a blocked thread will <em>eventually</em> acquire the lock–is often good enough, and is far less expensive to deliver. In most cases, the performance benefits of nonfair locks outweight the benefits of fair queueing. Don’t pay for fairness if you don’t need it.</p>
<p>Fair locks tend to work best when they are held for a relatively long time or when the mean time between lock requests is relatively long. In these cases, the condition under which barging provides a throughput advantage–when the lock is unheld but a thread is currently waking up to claim it–is less likely to hold.</p>
<p>Like the default <code>ReentrantLock</code>, intrinsic locking offers no deterministic fairness guarantees, but the statistical faireness guarantees of most locking implementations are good enough for almost all situations.</p>
<h2 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h2><p><code>ReentrantLock</code> implements a standard mutual exclusion lock: at most one thread at a time can hold a <code>ReentrantLock</code>. But mutual exclusion is frequently a stronger locking discipline than needed to preserve data integrity, and thus limits concurrency more than necessary. Mutual exclusion is a conservative locking strategy that prevents writer/writer and writer/reader overlap, but also prevents reader/reader overlap. In many cases, data structures are “read-mostly”–they are mutable and are sometimes modified, but most access involve only reading. In these cases, it would be nice to relax the locking requirements to allow multiple readers to access the data structure at once. As long as each thread is guaranteed an update-to-date view of the data and no other thread modifies the data while the readers are viewing it, there will be no problems. This is what read-write locks allow: a resource can be accessed by multiple readers or single writer at a time, but not both.</p>
<p>To read data guarded by a <code>ReadWriteLock</code> you must first acquire the read lock, and to modify data guarded by a <code>ReadWriteLock</code> you must first acquire the write lock:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ReadWriteLock</span> </span>&#123;</span><br><span class="line">    <span class="function">Lock <span class="title">readLock</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">Lock <span class="title">writeLock</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In practice, read-write locks can improve performance for frequently accessed read-mostly data structures on multiprocessor system; under other conditions they perform slightly worse than exclusive locks due to their greater complexity.</p>
<p>The interaction between the read and write locks allows for a number of possible implementations. Some of the implementation options for a <code>ReadWriteLock</code> are:</p>
<ol>
<li><p><strong>Release preference.</strong> When a writer releases the write lock and both readers and writers are queued up, who should be given performance–readers, writers, or whoever asked first?</p>
</li>
<li><p><strong>Reader barging.</strong> If the lock is held by readers but there are waiting writters, should newly arriving readers be granted immediate access, or should they wait behind the writers? Allowing readers to barge ahead of writers enhances concurrency but runs the risk of starving writers.</p>
</li>
<li><p><strong>Reentrancy.</strong> Are the read and write locks reentrant?</p>
</li>
<li><p><strong>Downgarding.</strong> If a thread holds the write lock, can it acquire the read lock without releasing the write lock? This would let a writer “downgrade” to a read lock without letting other writers modify the guarded resouce in the meantime.</p>
</li>
<li><p><strong>Upgrading.</strong> Can a read lock be upgraded to a wirter lock in preference to other waiting readers or writers? Most read-write lock implementations do not support upgrading, because without an explicit upgrade operation it is deadlock prone. For example, there are two readers reading the data simultaneously since we don’t block multiple readers. And they both attempt to upgrade to a writer lock, they will wait for the release of the reader lock of each other, which causes a deadlock.</p>
</li>
</ol>
<p><code>ReentrantReadWriteLock</code> provides reentrant locking semantics for both locks and it can be constrcuted as nonfair (the default) or fair. With a fair lock, preference is given to the thread that has been waiting the longest; if the lock is held by readers and a thread reqeusts the write lock, no more readers are allowed to acquire the read lock until the writer has been serviced and releases the write lock. With a nonfair lock, the order in which threads are granted access is unspecified. Downgrading from writer to reader is permitted; upgrading from reader to writer is not.</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
        <tag>Book Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>Book Reading: Java Concurrency in Practice, Chapter 4</title>
    <url>/2021/01/18/book_reading_java_concurrency_4/</url>
    <content><![CDATA[<h2 id="Design-a-thread-safe-class"><a href="#Design-a-thread-safe-class" class="headerlink" title="Design a thread-safe class"></a>Design a thread-safe class</h2><p>The design process for a thread-safe class should include these three basic elements:</p>
<ol>
<li>Identify the variables that form the object’s state.</li>
<li>Identify the invariants that constrain the state variables.</li>
<li>Establish a policy for managing concurrent access to the object’s state.<a id="more"></a>
</li>
</ol>
<p>An object’s state starts with its fields, no matter they are primitive types or references to other objects. Objects and variables have a state space: the range of possible states they can take on. That is why we want to use <code>final</code> whenever possible since it can make the space state smaller and easier to reason about.</p>
<p>Operations may have postconditions that identify certain state transitions as invalid. When the next state is derived from the current state, the operation is necessarily a compound action. As the result, an object’s state could be a subset of the fields in the object graph rooted at that object.</p>
<p>Constraints placed on states or state transition by invariants and postconditions create additional synchronization or encapsulation requirements. A class can also have invariants that constrain multiple state variables, which create atomicity requirements: related variables must be fetched or updated in a single atomic operation.</p>
<p>Class invariants and method postconditons constrain the valid states and state transitions for an object, it is impossible to ensure thread safety without understanding an object’s invariants and postconditions.</p>
<p>In addition to that, some objects also have method with state-based preconditions, operations with state-based preconditions are called state-denpendent. In a concurrent program, it adds possibility of waiting until the precondition becomes true, and then proceeding with the operation.</p>
<p>Ownership is another thing needs to be considered when designing thread-safe class, since ownership implies control. Usually the object encapsulates the state it owns and owns the state it encapsulates, but once a mutable object gets published, you no longer have exclusive control, which will result in a “shared ownership”, a typical example is collection classes.</p>
<h2 id="Instance-confinement"><a href="#Instance-confinement" class="headerlink" title="Instance confinement"></a>Instance confinement</h2><p>If an object is not thread-safe, several techniques can still let it be used safely in a multithreaded program.</p>
<p>Encapsulating data within an object is one of the methods, which confines access to the data to the object’s method, making it easier to ensure that the data is always accessed with the appropriate lock held.</p>
<p>Example (Note class <code>Person</code> is not thread safe):</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonSet</span> </span>&#123;</span><br><span class="line">    <span class="meta">@GuardedBy</span>(<span class="string">"this"</span>)</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Set&lt;Person&gt; mySet = <span class="keyword">new</span> HashSet&lt;Person&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">addPerson</span><span class="params">(Person p)</span> </span>&#123;</span><br><span class="line">        mySet.add(p);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">containsPerson</span><span class="params">(Person p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mySet.contains(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>It is still possible to violate confinement by pushlishing a supposedly confined object. Confined Objects can also escape by publishing other objects such as iterators or inner class instances that may indirectly publish the confined objects.</p>
<p>Another technique is to use java monitor pattern. An object following the java monitor pattern encapsulates all its mutable state and guards it with the object’s own instrinsic lock.</p>
<p>Example (Note any lock can be used as long as it is consistent):</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrivateLock</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Object myLock = <span class="keyword">new</span> Object();</span><br><span class="line">    <span class="meta">@GuardedBy</span>(<span class="string">"myLock"</span>) Widget widget;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">someMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span>(myLock) &#123;</span><br><span class="line">            <span class="comment">// Access widget</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>There are advantages to using a private lock object instead of an object’s intrinsic lock. Making the lock object private encapsulates the lock so that clent code cannot acquire it.</p>
<h2 id="Delegating-thread-safety"><a href="#Delegating-thread-safety" class="headerlink" title="Delegating thread safety"></a>Delegating thread safety</h2><p>Sometimes if you are using a thread-safe object, it is possible to make you class thread-safe without extra synchronization actions. We can also delegate thread safety to more than one underlying state variables as long as those underlying state variables are independent.</p>
<p>For example, the code below delegates thread safety to underlying <code>CopyOnWriteArrayList</code>, which is thread safe:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VisualComponent</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;KeyListener&gt; keyListeners = <span class="keyword">new</span> CopyOnWriteArrayList&lt;KeyListner&gt;();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;MouseListner&gt; mouseListners = <span class="keyword">new</span> CopyOnWriteArrayList&lt;MouseListener&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add Listeners...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Remove Listeners...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Note there is not relationship between the set of mouse listeners and key listeners, they are independent and that is why <code>VisualComponent</code> can delegate its thread safety obligations to two underlying thread-safe lists.</p>
<p>Most composite classes may have invariants that relate their component state variables. If a class has compound actions, delegation alone is again not a suitable approach for thread safety, and class must provide its own locking to ensure that compound actions are atomic.</p>
<p>If a state variable is thread-safe, does not participate in any invariants that constrain its value, and has no prohibited state transitions for any of its operation, then it can safely be published.</p>
<h2 id="Building-with-existing-thread-safe-classes"><a href="#Building-with-existing-thread-safe-classes" class="headerlink" title="Building with existing thread-safe classes"></a>Building with existing thread-safe classes</h2><p>The java class library contains many useful “building block” classes. Reusing existing classes is often preferable to creating new ones.</p>
<p>The safest way to add a new atomic operation is to modify the original class to support the desired operation, but this is not always possible because you may not have access to the source code or may not be free to modify it.</p>
<p>Another approach is to extend the class, assuming it was designed for extension. But extension is more fragile than adding code directly to a class, because the implementation of the synchronization policy is now distributed over multiple separately maintained source files. If the underlying class were to change its synchronization policy by choosing a different lock to guard its state variables, the subclass would subtly and silently break:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BetterVector</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">Vector</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">putIfAbsent</span><span class="params">(E x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> absent = !contains(x);</span><br><span class="line">        <span class="keyword">if</span> (absent)</span><br><span class="line">            add(x);</span><br><span class="line">        <span class="keyword">return</span> absent;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>A third strategy is to extend the functionality of the class without extending the class itself by placing extension code in a “helper” class. To make this approach work, we have to use the same lock that the <code>List</code> uses by using client-side locking.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListHelper</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;E&gt; list = Collections.synchronizedList(<span class="keyword">new</span> ArrayList&lt;E&gt;());</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">putIfAbsent</span><span class="params">(E x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span>(list) &#123;</span><br><span class="line">            <span class="keyword">boolean</span> absent = !list.contains(x);</span><br><span class="line">            <span class="keyword">if</span> (absent)</span><br><span class="line">                list.add(x);</span><br><span class="line">            <span class="keyword">return</span> absent;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Everytime we use this approach, we must make sure we know what lock the library class uses, otherwise we may put locking code into classes that are totally unrelated.</p>
<p>There is a less fragile alternative for adding an atomic operation to an existing class, composition:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ImprovedList</span>&lt;<span class="title">T</span>&gt; <span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;T&gt; list;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ImprovedList</span><span class="params">(List&lt;T&gt; list)</span> </span>&#123; <span class="keyword">this</span>.list = list; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">putIfAbsent</span><span class="params">(T x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> contains = list.contains(x);</span><br><span class="line">        <span class="keyword">if</span> (contains)</span><br><span class="line">            list.add(x);</span><br><span class="line">        <span class="keyword">return</span> !contains;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123; list.clear(); &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// ...similar delegate methods</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In effect, we used the java monitor pattern to encapsulate an existing <code>List</code>, and this is guaranteed to provide thread safety so long as our class holds the only reference to the underlying <code>List</code>.</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
        <tag>Book Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>The Java Memory Model</title>
    <url>/2021/01/17/java_memory_model/</url>
    <content><![CDATA[<h2 id="什么是内存模型？我们为什么需要一个内存模型？"><a href="#什么是内存模型？我们为什么需要一个内存模型？" class="headerlink" title="什么是内存模型？我们为什么需要一个内存模型？"></a>什么是内存模型？我们为什么需要一个内存模型？</h2><p>我们之前在详解<a href="https://kanrourou.github.io/2021/01/13/understand_synchronized_keyword/" target="_blank" rel="noopener"><code>synchronized</code></a>、<a href="https://kanrourou.github.io/2021/01/15/understand_volatile_keyword/" target="_blank" rel="noopener"><code>volatie</code></a>和<a href="https://kanrourou.github.io/2021/01/17/understand_final_keyword/" target="_blank" rel="noopener"><code>final</code></a>的文章当中讲过，底层JVM、编译器、处理器执行指令的顺序并不保证和程序员所写的代码的顺序一样。在单线程中，只要遵从<code>as-if-serial</code>语义，就可以进行重排，所以对于程序员来说，底层的实现只是造成了一个程序是按照自己的代码顺序执行的假象。<br><a id="more"></a><br>在多线程环境中，如果不进行额外的synchronization的操作，像单线程一样的线性执行是没有办法得到保证的。JMM的作用有两方面：</p>
<ol>
<li>要给开发者提供一个尽可能简单的，可以预测的多线程开发方式。</li>
<li>同时又要尽可能减少对底层JVM、硬件的限制，在保证1的前提下，对程序进行优化。</li>
</ol>
<p>在一个共享内存的多处理器架构下，每个处理器都会有自己缓存，这些处理器会定期地从主内存里读取数据来更新自己的缓存。而由于硬件上的差异，不同的处理器所提供的缓存一致性是不一样的。这就需要一个内存模型来告诉程序，其可以从内存系统中得到什么保证，并且可以通过插入一下特殊指令，比如内存屏障(memory barriers)，来保证在访问共享变量的时候能够得到一些额外的保证。</p>
<p>为了让开发者不需要接触到这些底层的不同和实现细节，JMM提供了一系列保证来判断在多线程环境下指令发生的先后顺序。同时，JVM处理了JMM与不同平台内存系统之间的差异性，通过在适当的地方插入内存屏障，来保证JMM对开发者的保证不会变。</p>
<p>简而言之，JMM定义了在多线程环境下所有操作的一个偏序。所谓偏序，即集合里的任意两个元素不一定能互相比较，这个集合当中，只有一部分元素的先后顺序是可以确定的。而这种保证，就是<em>happens-before</em>规则。</p>
<h2 id="Happens-Before规则"><a href="#Happens-Before规则" class="headerlink" title="Happens-Before规则"></a>Happens-Before规则</h2><p>Happens-Before规则提供了以下保证，摘抄<em>Java Concurrency in Practice</em>原文如下：</p>
<ol>
<li><strong>Program order rule.</strong> Each action in a thread <em>happens-before</em> every action in that thread that comes later in the program order.</li>
<li><strong>Monitor lock rule.</strong> An unlock on a mointor lock <em>happens-before</em> every subsequent lock on that same monitor lock. This in true for both explicit lock and intrinsic lock.</li>
<li><strong>Volatile variable rule.</strong> A write to a <code>volatile</code> field <em>happens-before</em> every subsequent read of that same field.</li>
<li><strong>Thread start rule.</strong> A call to <code>Thread.start</code> on a thread <em>happens-before</em> every action in the started thread.</li>
<li><strong>Thread termination rule.</strong> Any action in a thread <em>happens-before</em> any other thread detects that thread has terminated, either by successfully return from <code>Thread.join</code> or by <code>Thread.isAlive</code> returning false.</li>
<li><strong>Interruption rule.</strong> A thread calling <code>interrupt</code> on another thread <em>happens-before</em> the interrupted thread detects the interrupt (either by have <code>InterruptedException thrown</code>, or invoking <code>isInterrupted</code> or <code>interrupted</code>).</li>
<li><strong>Finalizer rule.</strong> The end of a constructor for an object <em>happens-before</em> the start of the finalizer for that object.</li>
<li><strong>Transitivity.</strong> If A <em>happens-before</em> B, and B <em>happens-before</em> C, then A <em>happens-before</em> C.</li>
</ol>
<p>以上八条规则虽然简单，但在现实中用于判断不同线程之前的先后关系和可见性的时候十分方便。我们用在这篇<a href="https://kanrourou.github.io/2021/01/15/understand_volatile_keyword/" target="_blank" rel="noopener">文章</a>中用过的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> ready;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> number;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReaderThreader</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!ready);</span><br><span class="line">            System.out.println(number);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> ReaderThread().start();</span><br><span class="line">        number = <span class="number">42</span>;</span><br><span class="line">        ready = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>假设线程A先执行了<code>main</code>方法，并且对<code>ready</code>进行写入。之后线程B执行<code>run()</code>方法读取<code>ready</code>的值，此时<code>number</code>的值对线程B可见吗？我们用<em>happens-before</em>规则判断：</p>
<ol>
<li>由规则3可知，第15行先与第7行。</li>
<li>由规则1可知，第7行先与第8行。</li>
<li>由规则1可知，第14行先与第15行。</li>
<li>由规则8可知，第14行先与第15行，先于第7行，先于第8行。所以对<code>number</code>赋值42是对线程B可见的。</li>
</ol>
<p>我们刚刚说过了，JMM定义的顺序只是集合的偏序，也就是任何两个不满足<em>happens-before</em>的操作，其先后顺序是没有任何保障的。</p>
<p>除此之外，JMM还对一些class library提供了<em>happens-before</em>保证：</p>
<ol>
<li>Placing an item in a thread-safe collection <em>happens-before</em> another thread retrieves that item from the collection.</li>
<li>Counting down on a <code>CountDownLatch</code> <em>happens-before</em> a thread returns from <code>await</code> on that latch.</li>
<li>Releasing a permit to a <code>Semaphore</code> <em>happens-before</em> acquiring a permit from that same <code>Samephore</code>.</li>
<li>Actions taken by the task represented by a <code>Future</code> <em>happens-before</em> another thread successfully returns from <code>Future.get</code>.</li>
<li>Submittig a <code>Runnable</code> or <code>Callable</code> to an <code>Executor</code> <em>happens-before</em> the task begins execution.</li>
<li>A thread arriving at a <code>CyclicBarrier</code> or <code>Exchanger</code> <em>happens-before</em> the other threads are released from that same barrier or exchange point. If <code>CyclicBarrier</code> uses a barrier action, arriving at the barrier <em>happens-before</em> the barrier action, which in turn <em>happens-before</em> threads are released from the barrier.</li>
</ol>
<h2 id="Safe-Publication-and-Initialization"><a href="#Safe-Publication-and-Initialization" class="headerlink" title="Safe Publication and Initialization"></a>Safe Publication and Initialization</h2><p>我们在详解<code>final</code>这篇<a href="https://kanrourou.github.io/2021/01/17/understand_final_keyword/" target="_blank" rel="noopener">文章</a>中聊过这个问题，有多种方法可以保证safely publish an object。这里我们不细聊这个话题，来看一些例子。</p>
<p>我们可以通过保证原子性来保证对象被安全初始化：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SafeInitialization</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Resource resource;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">static</span> Resource <span class="title">getInstance</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (resource == <span class="keyword">null</span>)</span><br><span class="line">            resource = <span class="keyword">new</span> Resouce();</span><br><span class="line">        <span class="keyword">return</span> resouce;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>synchronized</code>保证了<code>resource</code>在初始化完成之前都不会被其他线程访问，所以这是线程安全的初始化。</p>
<p>我们也可以用static initializer来保证安全初始化：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EagerInitialization</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Resource resource = <span class="keyword">new</span> Resource();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Resource <span class="title">getResource</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> resource; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Static initializer的安全性是JVM提供的保证，因为JVM保证static initializer在对象被其他线程访问之前就会完成。因为JVM在调用static initializer的时候会获取锁，这个所会在其他线程确认这个类被loaded的时候获取，所以可以保证static initializer的写都立马对其他线程可见。所以在不需要其他同步操作的情况下，就可以保证初始化安全性。</p>
<p>那么在结合上面两个技巧的情况下，我们可以实现不需要额外同步操作的线程安全版本的lazy initialization方法（另一种方法是DCL，我们在这篇<a href="https://kanrourou.github.io/2021/01/15/understand_volatile_keyword/" target="_blank" rel="noopener">文章</a>中讲过）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ResourceFactory</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ResourceHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Resource resource = <span class="keyword">new</span> Resource();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Resource <span class="title">getResouce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ResourceHolder.resource;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>ResourceHodler</code>的<code>resource</code>域是static initialized的，所以其保证初始化的安全性。<code>getResource</code>只有在被第一次调用的时候，才会初始化<code>resource</code>，所以其为lazy initialization。</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解final关键字</title>
    <url>/2021/01/17/understand_final_keyword/</url>
    <content><![CDATA[<h2 id="final的基本语义"><a href="#final的基本语义" class="headerlink" title="final的基本语义"></a>final的基本语义</h2><p><code>final</code>在java中是非常常用的关键字，其语义和C++中的<code>constant</code>有类似之处，都代表不变的意思，其可以用在以下地方：</p>
<ol>
<li>修饰变量，成员变量或者本地变量均可。</li>
<li>修饰方法的参数。</li>
<li>修饰方法。</li>
<li>修饰类。<a id="more"></a>
</li>
</ol>
<h3 id="final变量"><a href="#final变量" class="headerlink" title="final变量"></a>final变量</h3><p><code>final</code>修饰的primitive常量有两种用法：</p>
<ol>
<li>compile-time就知道变量值的情况。</li>
<li>run-time才知道变量值的情况。</li>
</ol>
<p>比如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalData</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> number1 = <span class="number">9</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> number2 = rand.nextInt(<span class="number">10</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对compile-time就知道常量值的情况，编译器可以把一些计算放在compile-time，这样可以减少一些run-time的overhead。</p>
<p>当<code>final</code>修饰的是引用的时候，只代表这个引用是常量，也就是被修饰的引用不能重新指向其他的变量，但是引用指向的实例是可以被更改的。Java并不提供关键字来修饰某个引用指向实例本身是不可更改的，但是用户可以自己定义immutable object，一个很好地例子就是java的string类。</p>
<p>无论<code>final</code>修饰的是成员变量还是本地变量，java都允许两种赋值方式：</p>
<ol>
<li>声明的时候直接赋值。</li>
<li>声明的时候不赋值，之后在赋值，但是只能赋值一次。</li>
</ol>
<p>例子如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalDataInitialization</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> number = <span class="number">9</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FinalDataInitialization</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Do something...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalDataInitialization</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> number;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FinalDataInitialization</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        number = readDB();</span><br><span class="line">        <span class="comment">// Do something...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodA</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        number = <span class="number">9</span>; <span class="comment">// Illegal!!</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="final参数"><a href="#final参数" class="headerlink" title="final参数"></a>final参数</h3><p><code>final</code>修饰方法参数和修饰变量的语义差不多：</p>
<ol>
<li><code>final</code>修饰的primitive变量不允许在方法当中更改。</li>
<li><code>final</code>修饰的引用不能更改指向，但引用指向的对象本身可以被更改。</li>
</ol>
<h3 id="final方法"><a href="#final方法" class="headerlink" title="final方法"></a>final方法</h3><p><code>final</code>修饰方法一般有两个作用：</p>
<ol>
<li>声明方法不能被override。</li>
<li>在早期的java，编译器可以把优化成inline call，这样可以减少调用方法的overhead。在现在的版本中已经不需要。</li>
</ol>
<p>值得一提的是，所有<code>private</code>的方法都是implicitly <code>final</code>的，因为其不对子类可见，子类当然没法override，子类强行定义的话只会创建一个新的方法，而不是覆写父类的方法。</p>
<p>被<code>final</code>修饰的方法依然可以被重载。</p>
<h3 id="final类"><a href="#final类" class="headerlink" title="final类"></a>final类</h3><p>被<code>final</code>修饰的类无法被继承：</p>
<ol>
<li>其成员变量可以自行决定是否要用<code>final</code>修饰。</li>
<li>所有方法都是implicitly <code>final</code>的，因为无法被继承，自然不会有子类去override。</li>
</ol>
<h2 id="final在多线程中的语义"><a href="#final在多线程中的语义" class="headerlink" title="final在多线程中的语义"></a>final在多线程中的语义</h2><h3 id="final与有序性"><a href="#final与有序性" class="headerlink" title="final与有序性"></a>final与有序性</h3><p>JMM对<code>final</code>域的重排规则是：</p>
<ol>
<li>禁止把对<code>final</code>域的写重排到当前对象构造函数之外。</li>
<li>如果<code>final</code>修饰的是引用，那么禁止对<code>final</code>修饰的引用的成员变量的写入和构建的对象被赋值到引用上操作的重排序。</li>
</ol>
<p>我们来看下面的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Data</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> num;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> finalNum;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Data</span><span class="params">(<span class="keyword">int</span> num, <span class="keyword">int</span> finalNum)</span> [</span></span><br><span class="line"><span class="function">        <span class="keyword">this</span>.num </span>= num;</span><br><span class="line">        <span class="keyword">this</span>.finalNum = finalNum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FinalDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Data data;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Data finalData;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        data = <span class="keyword">new</span> Data(<span class="number">1</span>, <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (data != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> num = data.num;</span><br><span class="line">            <span class="keyword">int</span> finalNum = data.finalNum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeFinal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        finalData = <span class="keyword">new</span> Data(<span class="number">3</span>, <span class="number">4</span>);</span><br><span class="line">        finalData.num = <span class="number">5</span>;</span><br><span class="line">    &#125;	</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">readFinal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (finalData != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> num = finalData.num;</span><br><span class="line">            <span class="keyword">int</span> finalNum = finalData.finalNum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们先看对<code>data</code>的操作，假设线程A执行<code>write()</code>的操作，随后线程B执行<code>read()</code>:</p>
<ol>
<li>由于规则1的存在，<code>final</code>域在<code>data</code>引用对线程B可见的时候可以保证已经赋值了。</li>
<li>所以只要线程B可以看见引用，那么可以保证<code>final</code>域的值对线程B可见。</li>
<li>对于普通域，对普通域的赋值可能重排到构造函数之外：比如可能先写入default value，之后再赋值。</li>
<li>所以对于普通域，<code>read()</code>的操作读取的结果并不一定是1。</li>
</ol>
<p>对于<code>finalData</code>的操作，我们仍然假设线程A执行<code>writeFinal()</code>，随后线程B执行<code>readFinal()</code>：</p>
<ol>
<li>对于规则2的存在，<code>final</code>修饰的引用的成员域，在对引用可见的时候都已经赋值了。</li>
<li>所以只要线程B可以看见引用，<code>finalData</code>中的<code>num</code>和<code>finalNum</code>的值(3,4)都对线程B可见。</li>
<li>注意第28行对<code>finalData.num</code>赋值5的操作并无此可见性保证。需要保证这个成员域的可见，可以考虑使用<code>volatile</code>。</li>
</ol>
<h3 id="final与可见性"><a href="#final与可见性" class="headerlink" title="final与可见性"></a>final与可见性</h3><p>一般而言，影响可见性的有两点：</p>
<ol>
<li>内存和CPU缓存的不一致性。</li>
<li>底层编译器和处理器对指令的重排。</li>
</ol>
<p>对于<code>final</code>修饰的primitive type，由于其不可修改性，所以不存在1的问题，那么<code>final</code>所禁止的重排可以保证引用可见时，其已经被赋值，所以可以保证可见性。</p>
<p>对于<code>final</code>修饰的引用：</p>
<ol>
<li>同样由于<code>final</code>所禁止的重排规则，在引用可见的时候，所有成员变量的值已经可见，所以可以保证<strong>初始化</strong>之后的可见性。</li>
<li>但是由于其并不禁止对引用指向对象的修改，所以之后的修改操作并不保证可见性。</li>
</ol>
<h3 id="final与原子性"><a href="#final与原子性" class="headerlink" title="final与原子性"></a>final与原子性</h3><p><code>final</code>没有任何原子性的保证。</p>
<h2 id="Immutable-Object与线程安全性"><a href="#Immutable-Object与线程安全性" class="headerlink" title="Immutable Object与线程安全性"></a>Immutable Object与线程安全性</h2><h3 id="构造函数中的this指针逃逸"><a href="#构造函数中的this指针逃逸" class="headerlink" title="构造函数中的this指针逃逸"></a>构造函数中的this指针逃逸</h3><p>在讲Immutale Object之前我们先来谈谈<code>this</code>指针逃逸的问题。</p>
<p>即使<code>final</code>可以保证修饰域的可见性，但是如果<code>this</code>在构造函数完成之前就对其他线程可见（逃逸）的话，这种情况下仍然会出问题。如下例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EscpaeDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> num;</span><br><span class="line">    <span class="keyword">public</span> EscapeDemo escapeDemo;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">EscapeDemo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        num = <span class="number">5</span>;</span><br><span class="line">        escapeDemo = <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于第6行和第7行可能没有数据依赖，可能重排。那么假设先执行第7行，此时可能出现的情况是:</p>
<ol>
<li>escapeDemo引用，也就是this引用已经对其他线程可见，但<code>final</code>域还没有赋值。</li>
<li>另外一个线程读取escapeDemo引用，进而读取<code>final</code>域，然而此时<code>final</code>域还没有被赋值。</li>
</ol>
<p>我们可以看到this指针逃逸带来的问题，就是在对象还没有被完全初始化之前，其就对其他线程可见了，这是一个十分容易导致错误的问题。当然上面的例子十分明显，还有一些不那么明显的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThisEscape</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ThisEscape</span><span class="params">(EventSource source)</span> 【</span></span><br><span class="line"><span class="function">        source.<span class="title">registerListener</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            new EventListener()</span> </span>&#123;</span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onEvent</span><span class="params">(Event e)</span> </span>&#123;</span><br><span class="line">                    doSomething(e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这种情况乍看之下好像没有问题，但是<code>EventListener</code>实例其实包含了一个隐式的<code>this</code>指针，因为其调用了对象的<code>doSomething()</code>方法，这种情况下<code>this</code>指针也是逃逸。如果在对象初始化完成之前，<code>doSomething()</code>方法就被调用，就很有可能出问题。</p>
<p>上面的代码可以换成下面安全的写法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SafeListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> EventListener listener;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SafeListener</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        listener = <span class="keyword">new</span> EventListener() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onEvent</span><span class="params">(Event e)</span> </span>&#123;</span><br><span class="line">                doSomething(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SafeListner <span class="title">getInstance</span><span class="params">(EventSource souce)</span> </span>&#123;</span><br><span class="line">        SafeListner safe = <span class="keyword">new</span> SafeListener();</span><br><span class="line">        source.registerListener(safe.lisener);</span><br><span class="line">        <span class="keyword">return</span> safe;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样的话，保证了<code>SafeListener</code>在接受到任何的event之前就已经完成了初始化，从而解决了<code>this</code>逃逸的问题。</p>
<h3 id="Immutable-Objet"><a href="#Immutable-Objet" class="headerlink" title="Immutable Objet"></a>Immutable Objet</h3><p>一个对象是<em>immutable</em>的，如果其满足下面三个条件：</p>
<ol>
<li>其状态在初始化完成时候无法更改，换句话说，不会提供可能修改对象状态的方法。</li>
<li>所有成员域均用<code>final</code>修饰。</li>
<li>构造过程中<code>this</code>指针不会逃逸。</li>
</ol>
<p><strong>Immutable object永远都是线程安全的。</strong></p>
<p>这个不难理解，因为当其初始化完成的时候，其内部的所有状态都对其他线程可见了；并且它一旦初始化完成，就不能更改，也就是只能被其他线程读，而不能写，自然就不存在race condition。</p>
<p>比如下面的例子，我们可以只用immutable object和<code>volatile</code>，就可以实现线程安全的class：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Immutable</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Cache</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BigInteger key;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BigInteger value;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Cache</span><span class="params">(BigInteger key, BigInteger value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> BigInteger <span class="title">getValue</span><span class="params">(BigInteger key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span> || !<span class="keyword">this</span>.key.equals(key)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ThreadSafe</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExpensiveService</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> volatie Cache cache = <span class="keyword">new</span> Cache(<span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processRequest</span><span class="params">(Request req, Response, resp)</span> </span>&#123;</span><br><span class="line">        BigInteger key = keyFromReq(req);</span><br><span class="line">        BigInteger value = cache.getValue(key);</span><br><span class="line">        <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">            value = expensiveCalculation(key);</span><br><span class="line">            cache = <span class="keyword">new</span> Cache(key, value);</span><br><span class="line">        &#125;</span><br><span class="line">        encodeIntoResponse(resp, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码是线程安全的：</p>
<ol>
<li><code>Cache</code> class保证了原子性，因为无论何时<code>key</code>和<code>value</code>都是同步更新的。并且在初始化完成之前是对其他线程不可见的，所以其他线程读取的时候，一定<code>key</code>和<code>value</code>都是同步更新了之后的值。</li>
<li><code>volatile</code>保证了可见性，也就是<code>cache</code>被更新了之后，引用是立马对其他线程可见的。</li>
<li>假设有一个线程去更新<code>cache</code>，这个操作并不影响现在所有读取当前<code>cache</code>引用的线程，因为<code>cache</code>是immutable object，其他线程不能更改，只能重新<code>new</code>一个。</li>
</ol>
<p>通过以上例子我们可以看出immutable object可以如何帮助我们在不用<code>synchronized</code>的情况下保证线程安全。</p>
<h3 id="Safe-Publication"><a href="#Safe-Publication" class="headerlink" title="Safe Publication"></a>Safe Publication</h3><p>我们定义publishing一个对象的意思为，让对象在当前的scope之外可见，比如：</p>
<ol>
<li>赋值给其他的引用。</li>
<li>在方法中返回一个引用。</li>
<li>或者是将当前引用传递给其他的方法。</li>
</ol>
<p>而在多线程环境中，对于mutable object，我们很容易不注意就会unsafely publish，比如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UnsafePublish</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> Demo demo;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">UnsafePublish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        demo = <span class="keyword">new</span> Demo();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们在这篇<a href="https://kanrourou.github.io/2021/01/15/understand_volatile_keyword/" target="_blank" rel="noopener">文章</a>里讲过，<code>new</code>的操作不是原子性的，所以引用可见的时候，其还没初始化完全，所以就会出现unsafe publish的情况。</p>
<p>对于mutable object来讲，我们希望可以保证当其引用可见的时候，其内部状态也已经可见了，这样才能保证safe publication，一般来讲有下列方法：</p>
<ol>
<li>在static initizlier里初始化要publish的对象。</li>
<li>用<code>volatile</code>修饰要publish的对象。</li>
<li>用<code>AtomicReference</code>存要publish的对象。</li>
<li>用<code>final</code>修饰其引用，并且保证其在初始化的时候不会发生<code>this</code>逃逸。</li>
<li>用锁来guard每次对publish的引用的读和写。</li>
</ol>
<p>解释如下：</p>
<ol>
<li>第一点是JVM的保证，static initializer的调用在构造函数之前，可以保证所有初始化的field在引用可见的时候已经可见了。</li>
<li>这点我们在上面的文章里讲过，<code>volatile</code>禁止重排序从而保证可见性。</li>
<li>3和5本质上是一样的，通过强制原子操作从而避免race condition。并且本身也有可见性的保证。</li>
<li>本文已经重点讲过，不再赘述。</li>
</ol>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解volatile关键字</title>
    <url>/2021/01/15/understand_volatile_keyword/</url>
    <content><![CDATA[<h2 id="volatile与可见性"><a href="#volatile与可见性" class="headerlink" title="volatile与可见性"></a>volatile与可见性</h2><p>我们还是先来看一个例子，这个例子在<code>synchronized</code>这篇<a href="https://kanrourou.github.io/2021/01/13/understand_synchronized_keyword/" target="_blank" rel="noopener">文章</a>中用过:<br><a id="more"></a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntegerIncrementer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> counter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        counter++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们之前是用<code>synchronized</code>关键字让现场在修改完变量后强制刷新内存，让修改结果对其他线程可见。其实<code>volatile</code>可以达到同样的效果，即修改后的变量可以保证对其他线程可见。</p>
<p>具体实现的原理是，对<code>volatile</code>进行的操作最后在汇编语言中会带有<em>Lock</em>前缀，<em>Lock</em>前缀具有以下的作用：</p>
<ol>
<li>把当前变量所在CPU缓存行的数据写回内存。</li>
<li>让其他CPU包含了该地址的缓存行失效，也就是线程下一次读取共享变量必须强制去内存读取。</li>
</ol>
<p>注意缓存行是CPU缓存中最小的读写单位，一般一个缓存行中会包含多个共享变量，并且这些变量之间可以没有任何关系。频繁地使缓存失效会降低缓存命中率，从而影响性能。这就是伪共享的问题，伪共享可以通过字节填充来解决，这里不展开讨论。</p>
<p>总之<code>volatile</code>可以通过这样的机制来保证可见性。</p>
<h2 id="volatile与有序性"><a href="#volatile与有序性" class="headerlink" title="volatile与有序性"></a>volatile与有序性</h2><p><code>volatile</code>的另一个特性是可以禁止指令的重排，我们来看这个例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> ready;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> number;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReaderThreader</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!ready);</span><br><span class="line">            System.out.println(number);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> ReaderThread().start();</span><br><span class="line">        number = <span class="number">42</span>;</span><br><span class="line">        ready = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>乍看之下，似乎最后打印出来的是42, 但是我们还是在上面那篇文章中介绍过，编译器和处理器会在遵从<code>as-if-serial</code>的语义下对指令进行重排。代码14和15行之前没有任何依赖关系，那么完全可能出现：</p>
<ol>
<li>线程A先执行15行，CPU time结束，发生context switch。</li>
<li>线程B执行<code>run()</code>方法，打印出来的结果是0。</li>
</ol>
<p><code>volatile</code>是通过插入内存屏障来防止重排，这里我们不展开讨论。一般而言，其会禁止下列重排：</p>
<ol>
<li>第二个操作是<code>volatile</code>写，第一个操作为普通读写时，禁止重排序。</li>
<li>第一个操作是<code>volatile</code>读，第二个操作位普通读写时，进制重排序。</li>
<li>禁止对<code>volatile</code>修饰的变量读写相关操作的重排序。</li>
</ol>
<p>那么为什么要禁止普通读写和<code>volatile</code>读写之间的重排序呢？我们还是举上面的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> ready;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReaderThreader</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (!ready);</span><br><span class="line">            <span class="keyword">int</span> number = readDB(<span class="string">"key"</span>);</span><br><span class="line">            System.out.println(number);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> ReaderThread().start();</span><br><span class="line">        writeDB(<span class="string">"key"</span>, <span class="number">42</span>);</span><br><span class="line">        ready = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里<code>ready</code>已经被<code>volatile</code>修饰，那么假设不禁止情况1下的重排，那么第14和15行由于没有数据依赖，仍然有可能重排，那么可能出现以下情况：</p>
<ol>
<li>线程A先执行15行，发生context switch。</li>
<li>线程B执行<code>run()</code>方法，读取DB的时候key不存在，或者读到stale data。</li>
</ol>
<p>对于情况2，类似地，第6行和第7行的顺序可能重排，第7行的语句可能先被执行，将结果缓存，等到第6行判断为真的时候再赋值，那么可能出现这种情况：</p>
<ol>
<li>线程A执行第7行，有可能读到stale data，缓存结果，发生context switch。</li>
<li>线程B执行<code>main</code>方法，更新key的值。</li>
<li>线程A执行第6行，判断为真，将缓存的stale data赋值给<code>number</code>。</li>
</ol>
<p>因为会出现以上的情况，所以我们需要禁止普通读写和<code>volatile</code>读写的重排序。那么对<code>volatile</code>修饰变量操作重排序的禁止，有一个大家耳熟能详的例子，就是DCL(Double Check Lock):</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DCLDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> DCLDemo instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> DCLDemo <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(DCLDemo.class) &#123;</span><br><span class="line">                <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    instance = <span class="keyword">new</span> DCLDemo();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上是线程安全版的Singleton的实现方法，其中有两个细节：</p>
<ol>
<li><code>instance == null</code>的检查要做两次，因为第一次检查完到获取锁中间，可能有其他线程已经完成了实例化从同步块中出来了。</li>
<li><code>instance</code>需要用<code>volatile</code>修饰。</li>
</ol>
<p>这里<code>volatile</code>的作用是防止指令的重排序，因为<code>new</code>的操作不是原子性的，它会分为三步：</p>
<ol>
<li>分配内存区间。</li>
<li>调用构造函数初始化实例。</li>
<li>将初始化完毕的实例赋值给引用。</li>
</ol>
<p>所以其中2和3是可能重排，那么一旦执行顺序变为1-&gt;3-&gt;2，那么其他线程进来的时候，<code>instance</code>可能并不为<code>null</code>，但是此时publish的实例是没有初始化完成的，就很有可能出错。所以我们必须用<code>volatile</code>修饰<code>instance</code>来防止可能的指令重排。</p>
<h2 id="volatile与原子性"><a href="#volatile与原子性" class="headerlink" title="volatile与原子性"></a>volatile与原子性</h2><p><code>volatile</code>并不对原子性有任何保证，所以需要原子性的时候，需要和其他保证原子性的关键字搭配使用，比如<code>synchronized</code>。<br>但是值得一提的是<code>volatile</code>修饰的64位变量(如long，double)，其读写操作在32位JVM中会具有原子性。</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解synchronized关键字</title>
    <url>/2021/01/13/understand_synchronized_keyword/</url>
    <content><![CDATA[<h2 id="synchronized与原子性"><a href="#synchronized与原子性" class="headerlink" title="synchronized与原子性"></a>synchronized与原子性</h2><p>先来看一个大家很熟悉的例子：<br><a id="more"></a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntegerIncrementer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段很简单的代码，在单线程中不会有任何问题。但是如果在多线程的环境当中，运行结果就很有可能并不是我们所想的情况：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> IntegerIncrementer incrementer = <span class="keyword">new</span> IntergerIncrementer();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Demo());</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"result: "</span> + incrementer.getCount());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        incrementer.increase();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上代码开了1000个线程，每个线程做的事情很简单，就是让incrementer自增，但是最后的结果却并不一定是1000。这是因为<code>count++</code>并不是一个原子性的操作，所谓原子性，就是指线程在执行这个指令的时候不会被打断，不会发生context switch。一个<code>count++</code>的操作，实际上包含了以下三步：</p>
<ol>
<li>读取count的值。</li>
<li>对count加一。</li>
<li>将加一后的值赋值给count。</li>
</ol>
<p>即使一般而言，1和3的操作在java中都被认为是具有原子性的（<strong>注意long和double在32位架构的CPU下不是原子操作，会分开成两次32位的读或者写</strong>），但是这三种操作组合起来并不具有原子性。比如可能发生以下情况：</p>
<ol>
<li>线程A读取了count的值为9，对其加一。</li>
<li>在线程A赋值之前，线程B也读取了count的值为9，对其加一。</li>
<li>线程A对count赋值为10。</li>
<li>线程B对count赋值为10。</li>
</ol>
<p>2的情况中，我们并不一定要求在线程A赋值之前B去读count这个情况才可能发生，因为即使线程A写入了，也不一定对B可见，这个我们之后在讨论。</p>
<p>在以上的情况中，count本应该最后变为11，但是最后的值却为10。很明显，在多线程环境中，我们无法确定程序最后输出的结果是什么，因为其完全取决于线程运行的情况。所以我们希望<code>count++</code>这个操作可以具有原子性，为了达到这个目的，我们可以用<code>synchronized</code>关键字。</p>
<p><code>synchronized</code>可以用在以下场景：</p>
<ol>
<li>静态方法: <code>public static synchronized void method() { ... }</code></li>
<li>实例方法: <code>public synchronized void method() { ... }</code></li>
<li>类对象: <code>synchronized (Demo.class) { ... }</code></li>
<li>实例对象: <code>synchronized (this) { ... }</code></li>
</ol>
<p>每一个java的对象都有对应的monitor lock，这个monitor lock会在进入synchronized block的时候被线程自动获取，然后在离开的时候释放。这个锁一旦被某个线程获取，其他线程都无法获取，只能block，等占有的线程释放之后，再尝试获取。值得注意的是，java的monitor lock是可以重复获取的，如果一个线程已经获取了这个锁，那么当它再次请求的时候，这个锁对应的计数器会加一，每一次离开synchronized block都会减一，直到减为0，锁就会释放。举个例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">do</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//Do something...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ChildClass</span> <span class="keyword">extends</span> <span class="title">BaseClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">do</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//Do something...</span></span><br><span class="line">        <span class="keyword">super</span>.<span class="keyword">do</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果我们直接调用<code>ChildClass</code>的<code>do()</code>方法，那么当前线程会获取<code>ChildClass</code>和<code>BaseClass</code>的monitor lock，那么当其调用<code>super.do()</code>的时候，会尝试再次获取<code>BaseClass</code>的monitor lock，如果不允许重复获得锁的话，这个锁是被当前线程拥有，所以不可能再次获得，那么只会deadlock。</p>
<p>需要注意的是对象的monitor lock的和对选哪个本身的状态并没有太大的关系。获得了对象的monitor lock并不会防止其他线程访问对象，只会防止其他线程获得相同的monitor lock，其他线程仍然可以访问对象没有被<code>synchronized</code> guard的代码。</p>
<p>具体是使用synchronized method还是synchronized block，这取决与具体的情况，但是一般都需要注意避免在里面放入一些费时的操作，比如昂贵的计算、网络或者I/O请求。</p>
<h2 id="synchronized与可见性"><a href="#synchronized与可见性" class="headerlink" title="synchronized与可见性"></a>synchronized与可见性</h2><p>还是上面的例子，如果我们改成这样是不是就没问题了呢?</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntegerIncrementer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> counter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">increase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        counter++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>很遗憾，答案是否定的。这里又会涉及到另一个问题，就是可见性的问题。简而言之，就是线程A的操作不一定马上对线程B可见。在JMM(Java Memory Model)的设计中，共享变量储存在主内存当中，每一个线程又会有自己的工作内存，这一块区域只对这个线程可见，线程对共享变量进行操作的时候会先读取到工作内存，修改然后在写回去。那么完全可能出现以下情况：</p>
<ol>
<li>线程A从主内存读取counter，在工作内存中加一，写入工作内存的变量。</li>
<li>线程B从主内存读取counter。</li>
<li>线程A把counter写入主内存。</li>
</ol>
<p>这样一来线程B最后读到的数据是stale data，再一次地，程序的运行结果取决于线程的运行的状况，输出无法预测。</p>
<p>同样我们可以利用<code>synchrnized</code>来解决这个问题，<code>synchronized</code>可以保证线程在释放锁的时候强制将值刷新到主内存，这样当释放锁的时候，新的值就即使对其他线程可见，保证了对共享变量更改的可见性。</p>
<p>所以当对共享变量进行操作的时候，如果有线程写入的话，读和写都需要进行加锁。</p>
<p>当然我们也可以使用<code>volite</code>关键字来达到可见性，我们会在另外的文章中进行讨论。</p>
<h2 id="synchronized与有序性"><a href="#synchronized与有序性" class="headerlink" title="synchronized与有序性"></a>synchronized与有序性</h2><p>在编程语言中，程序员所写的代码的顺序和最后机器执行的顺序并不一定是一样的，这是因为底层的编译器和处理器，包括JVM会对指令进行优化，从而达到更好的performance。对于一段代码只要在遵从<code>as-if-serial</code>语义的前提下——即无论如何重排序，单线程执行的结果不会改变——就可以对指令进行重排。在JMM中，因为多线程的情况，其会限制一些指令的重排，当然程序员也可以利用一些关键字来防止重排，这里我们不做深入讨论。</p>
<p>这里有序性指的是，程序是否按照代码的顺序执行，不会被底层的一些处理而重排。</p>
<p><code>synchronized</code>并无法防止指令的重排，但其在一定程度上提供了有序性：</p>
<ol>
<li>所有synchronized block同时只能有一个线程进入，这保证了block之间的有序性。</li>
<li>其会防止释放monitor lock和在block中写入变量的指令之间的重排，这保证了释放锁的时候，更新的值已经写入了主内存。</li>
</ol>
<p>但是对于block中的指令，并没有办法防止重排。因为block中始终是单线程，只要遵从<code>as-if-serial</code>语义，即可重排。</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Java</category>
        <category>Concurrency</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title>Use Valine to set up blog comments and PV</title>
    <url>/2021/01/03/valine_for_pv_and_comments/</url>
    <content><![CDATA[<p>We have introduced one <a href="https://kanrourou.github.io/2019/03/18/hexo_next_page_user_views/" target="_blank" rel="noopener">way</a> before to configure blog PV by using the natrually supported LeanCloud counter in NexT theme. But this is somehow broken for my site, so I explored and switched to <a href="https://valine.js.org/" target="_blank" rel="noopener">Valine</a> which supports PV and comments without any backend changes.<br><a id="more"></a></p>
<h3 id="Set-up-LeanCloud"><a href="#Set-up-LeanCloud" class="headerlink" title="Set up LeanCloud"></a>Set up LeanCloud</h3><p>The LeanCloud set up is pretty similar to what have been explained in the article above, please refer to it for more details. In general, after creating your application, you will need to create <code>Counter</code> and <code>Comment</code> classes under <code>Storage-&gt;Objects</code>, note that the class name must not be changed. And the ACL permission needs to be set to allow all users to read &amp; write.</p>
<p><img src="/images/leancloud_classes_permission.png" alt></p>
<p>Navigate to the security page, turn off all services except LeanStorage, and add your blog domain to web secure domains.</p>
<p><img src="/images/leancloud_security.png" alt></p>
<h3 id="Update-config-file"><a href="#Update-config-file" class="headerlink" title="Update config file"></a>Update config file</h3><p>Go to this <a href="https://www.jsdelivr.com/package/npm/valine" target="_blank" rel="noopener">page</a> to access Valine CDN files.</p>
<p><img src="/images/valine_cdn.png" alt></p>
<p>Copy the script url and modify <code>themes/next/_config.yml</code> as below:<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Valine</span></span><br><span class="line"><span class="comment"># valine: //cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js</span></span><br><span class="line"><span class="comment"># valine: //cdnjs.cloudflare.com/ajax/libs/valine/1.3.4/Valine.min.js</span></span><br><span class="line"><span class="attr">valine:</span> <span class="attr">https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js</span></span><br></pre></td></tr></table></figure></p>
<p>Navigate to app keys page to acquire your <code>appid</code> and <code>appkey</code>.</p>
<p><img src="/images/lean_cloud_app_key.png" alt></p>
<p>Then turn on Valine in the config file:<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Valine</span></span><br><span class="line"><span class="comment"># More info available at https://valine.js.org</span></span><br><span class="line"><span class="attr">valine:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span> </span><br><span class="line"><span class="attr">  appid:</span> <span class="comment">#your id#</span></span><br><span class="line"><span class="attr">  appkey:</span> <span class="comment">#your key#</span></span><br><span class="line"><span class="attr">  notify:</span> <span class="literal">false</span> <span class="comment"># mail notifier, See: https://github.com/xCss/Valine/wiki</span></span><br><span class="line"><span class="attr">  verify:</span> <span class="literal">false</span> <span class="comment"># Verification code</span></span><br><span class="line"><span class="attr">  placeholder:</span> <span class="string">Just</span> <span class="string">go</span> <span class="string">go...</span> <span class="comment"># comment box placeholder</span></span><br><span class="line"><span class="attr">  avatar:</span> <span class="string">mm</span> <span class="comment"># gravatar style</span></span><br><span class="line"><span class="attr">  guest_info:</span> <span class="string">nick,mail,link</span> <span class="comment"># custom comment header</span></span><br><span class="line"><span class="attr">  pageSize:</span> <span class="number">10</span> <span class="comment"># pagination size</span></span><br><span class="line"><span class="attr">  visitor:</span> <span class="literal">true</span> <span class="comment"># leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors' for counter compatibility. Article reading statistic https://valine.js.org/visitor.html</span></span><br><span class="line"><span class="attr">  comment_count:</span> <span class="literal">true</span> <span class="comment"># if false, comment count will only be displayed in post page, not in home page</span></span><br></pre></td></tr></table></figure></p>
<p>You can also enable the <code>visitor</code> which will display the number of views of your posts. Notes this conflicts with LeanCloud counter so you need to turn it off in the config file.</p>
<p>Deploy the changes and you will see the comments and PV:</p>
<p><img src="/images/comments.png" alt></p>
<p><img src="/images/comments_pv_header_view.png" alt></p>
<h3 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h3><p>The PV counter uses title combing publish date as the key. To avoid that updating the article will cause the PV to be reset, you can add the publish date in you article:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">date: 2021-01-03 15:25:41</span><br></pre></td></tr></table></figure></p>
<p>And turn off the <code>future</code> in Hexo’s <code>_config.yml</code>.<br><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">future:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></p>
<p>So the posted date will not be changed after you modified it, and the previous PV count will be kept.</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>JavaScript</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>JavaScript</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper Reading: Kafka</title>
    <url>/2021/01/03/paper_reading_kafka/</url>
    <content><![CDATA[<p><a href="http://notes.stephenholiday.com/Kafka.pdf" target="_blank" rel="noopener">Kafka</a> is a distributed messaging system that developed for collecting and delivering high volumes of log data with low latency.<br><a id="more"></a></p>
<h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><p>A stream of message of a particular type is defined by a topic. A producer can publish messages to a topic. The pushed messages are then stored at a set of servers called brokers. </p>
<p>Kafka uses pull model instead of push, in which the broker forwards data to consumers, since each consumer can retrieve the messages at themaximum rate it can sustain and avoid being flooded by messages pushed faster than it can handle.</p>
<p>To subscribe a topic, a consumer first creates one or more message streams for the topic. The messages published to that topic will be evenly distributed into these sub-streams. The message stream iterator never terminates. If there are currently no more messages to consume, the iterator blocks until new messages are published to the topic.</p>
<p>Kafaka supports both the point-to-point delivery modelin which multiple consumers jointly consume a single copy of all messages in a topic, as well as the pub/sub model in which multiple consumers each retrieve its own copy of a topic.</p>
<p>To balance load, a topic is divided into multiple partitions and each broker stores one or more of those partitions. Multiple producers and consumers can publish and retrieve messages at the same time.</p>
<h2 id="Design-Principles"><a href="#Design-Principles" class="headerlink" title="Design Principles"></a>Design Principles</h2><p>Kafka has a very simple storage layout. Each partition of a topic corresponds to a logical log. Physically, a log is implemented as a set of segment files of approximately the same size (e.g. 1GB). Kafka flushes the segment file to disk only after a configurable number of messages have been published or a certain amount of time has elapsed, A message is only exposed to the consumer after it is flushed.</p>
<p>Each message in Kafka is addressed by its logical offset in the log. Thus the message ids are increasing but not consecutive. A consumer always consume messages from particular partition sequentially. Under the cover, the consumer is issuing asynchronous pull requests to the broker to have a buffer of data ready for the application to consume. Each pull request contains the offset of the message from which the consumption begins and an acceptable number of bytes to fetch. Each broker keeps in memory a sorted list of offsets as index, including the offset of the first message in every segment file.</p>
<p>Kafka avoid explicitly caching messages in memory at the Kafka layer. Instead, it relys on the underlying file system page cache which benefits the sequential access, normal operating system caching heuristics are very effective.</p>
<p>Kafka exploit the sendfile API to avoid extra copy from page cache to application buffer and kernel buffer, and efficiently deliver bytes in a log segment file from a broker to a consumer.</p>
<p>In Kafka, the information about how much each consumer has consumed is not maintained by the broker, but by the consumer itself. This design decision results in a stateless broker. However, this makes it tricky to delete a message since a broker doesn’t know whether all subscribers have consumed the message. Kafka solves this problem by using a simple time-based SLA for the retention policy.</p>
<p>One important benefit of this design is that a consumer can deliberately <strong>rewind</strong> back to an old offset and re-consume data. One example is that the consumer application might flush the data to disk periodically. If the consumer crashes, the unflushed data is lost. In this case, the consuemr can checkpoint the smallest offset of the unflushed messages and re-consume from that offset when it is restarted. Rewind is much easier to support in pull model than push model.</p>
<h2 id="Producer-amp-Consumer-Coordination"><a href="#Producer-amp-Consumer-Coordination" class="headerlink" title="Producer &amp; Consumer Coordination"></a>Producer &amp; Consumer Coordination</h2><p>Each producer can publish a message to either a random selected partition or a partition semantically determined by a partitioning key and a partitioning fucntion.</p>
<p>Each <strong>consumer group</strong> consists of one or more consumers that jointly consume a set of subscribed topics. Different consumer groups each independently consume the full set of subscribed messages and no coordination is needed across consumer groups.</p>
<p>To make the coordination easier, the first decision is to make a partition within a topic the smallest unit of parallelism. This means at any given time, all messages from one partition are consumed only by a single consumer within each consumer group. The second decision is to not have a master node, but instead let consumers coordinate among themselves in a decentralized fashion since adding master can complicated the system, for example, master failure needs to be handled.</p>
<p>Thus Kafka uses <a href="https://kanrourou.github.io/2021/01/02/paper_reading_zookeeper/" target="_blank" rel="noopener">ZooKeeper</a> for coordinating following tasks:</p>
<ol>
<li>Detecting the addition and the removal of brokers and consumers.</li>
<li>Triggering a rebalance process in each consumer when the above events happen.</li>
<li>Maintaining the consumption relationship and keeping track of the consumed offset of each partition (per consumer group).</li>
</ol>
<p>Specifically, when each broker or consumer starts up, it stores its information in a broker or consumr registry in ZooKeeper. The broker registry contains the broker’s host name and port, and the set of topics and partitions it stored on it. The consumer registry includes the consumer group to which a consumer belongs and the set of topics that it subscribes to. Each consumer group is associated with an ownership registry and an offset registry in ZooKeeper. The ownership registry has one path for every subscribed partition and the consumer which currently owns this partition. The offset registry stores last consumed offset of the messages in the partition.</p>
<p>The ZooKeeper node created for broker registry, consumer registry and ownership registry is ephemeral, and persistent for the offset registry. If a broker fails, all partition on it are automatically removed from the broker registry. Same as consumer, which causes it to lose its entry in the consumer registry and all partitions it owns in ownership registry. Each consumer registers a ZooKeeper watcher on both broker and consumer registry, and will be notified when ther is a broker set or consumer group change. A rebalance process will be initialized to determine the new subset of partition each consumer should consume from when receiving notification, please refer to the orginal article for more details.</p>
<p>The notification may come at slightly different times at the consuemrs. So it is possible that one consumer tries to take ownership of a partition stilled owned by another consumer. When this happens, the first consumer simply release all the partitions that it currently owns, wait a bit and retries the reblance process.</p>
<h2 id="Guarantees"><a href="#Guarantees" class="headerlink" title="Guarantees"></a>Guarantees</h2><p>In general, Kafka only guarantees at-least-once delivery. Most of time, the message is delivered exactly once to each consumer group. In case when a consumer process crashes without a clean shutdown, after it restarts, it might get duplicates after the last offset successfully commited to ZooKeeper.</p>
<p>Kafka guarantees that messages from a single partition are delivered to a consumer in order. However, there is no guarantee on the ordering of messages coming from differernt partitions.</p>
<p>To avoid log corruption, Kafka stores CRC (Cyclic Redundancy Check) for each message in the log.</p>
<p>The paper doesn’t discuss about replications in Kafka, but it should already be supported.</p>
]]></content>
      <categories>
        <category>System Infrastructure</category>
        <category>MessageQueue</category>
      </categories>
      <tags>
        <tag>Distributed System</tag>
        <tag>Infrastructure</tag>
        <tag>Paper Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper Reading: ZooKeeper</title>
    <url>/2021/01/02/paper_reading_zookeeper/</url>
    <content><![CDATA[<p><a href="https://www.usenix.org/legacy/events/atc10/tech/full_papers/Hunt.pdf" target="_blank" rel="noopener">ZooKeeper</a> is a service for coordinating processes of distributed applications, which provides wait-free coordination for Internet-scale systems.<br><a id="more"></a></p>
<h2 id="Design-Decisions"><a href="#Design-Decisions" class="headerlink" title="Design Decisions"></a>Design Decisions</h2><p>Moved away from implementing specific primitives on the server side, opted for exposing an API that enables application developers to implement their own primitives, which enables new primitives without requiring changes to the service core.</p>
<p>Moved away from blocking primitives, such as locks (e.g. Chubby). Since blocking primitives can cause, among other problems, slow or faulty clients to impact negatively the performance of faster clients. Instead, ZooKeeper implements an API that manipulates simple wait-free data objects (znodes) organized hierarchically as in file systems.</p>
<p>ZooKeepers guarantees two following properties for client operations:</p>
<ol>
<li>FIFO client order: all requests from <strong>a given client</strong> are executed in the order that they were sent by the client. Note this order guarantee is per client level, for example, read operation order is not guaranteed among clients, since read operations are handled locally by the connected server.</li>
<li>Linearizable writes: all requests that update the state of ZooKeeper are serializable and respect precendence. This is guaranteed by implementing a leader-based atomic broadcast protocol, called Zab.</li>
</ol>
<p>Improve read performace by caching data on the client side, for example, the process can cache the identifier fo the current leader instead of probing ZooKeeper every time in needs to know the leader. ZooKeepers uses a watch mechanism, with this mechanism, a client can watch for an update to a given data object and receive a notification upon an update.</p>
<h2 id="Service-Overview"><a href="#Service-Overview" class="headerlink" title="Service Overview"></a>Service Overview</h2><p>The ZooKeeper provides to its clients the abstraction of a set of data nodes (znodes), organized according to a hierarchical name space, referred by the standard UNIX notation for file system paths. All znodes store data, and all znodes, except for <strong>ephemeral znodes</strong>, can have children. There are two types of znodes that a client can create:</p>
<ol>
<li>Regular: Clients manipulate regular znodes by creating and deleting them explicitly.</li>
<li>Ephemeral: Clients create such znodes, and they either delete them explicitly, or let the system remove them automatically when the session that creates them terminates.</li>
</ol>
<p>ZooKeepers implements watches to allow clients to receive timely notification of chanes wihout requiring polling. Watches are one-time triggers associated with a session; they are unregistered once triggered or the session closes. Watches indicate that a change has happened, but do not provide the change. Session events, such as connection loss events, are also sent to watch callbacks so that clients knows that clients know that watch events may be delayed.</p>
<p>Znodes map to abstractions of the client application, typically corresponding to meta-data used for coordination purposes. Although znodes have not been designed for general data storage, ZooKeepers does allow clients to store some information that can be used for meta-data or configuration in a distributed computation. It also has associated meta-data with time stamps and version numbers which allow clients to keep track of its status.</p>
<p>A client connects to ZooKeeper and initiates a session. ZooKeeper considers a client faulty if it does not receive anything from its session for more than that timeout.</p>
<h2 id="APIs"><a href="#APIs" class="headerlink" title="APIs"></a>APIs</h2><p>The common used APIs provided by ZooKeeper are:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create(path, data, flags), where flags enables a client to select the type of znode: regular, ephemeral, and set the sequential flag, which is a monotonicaly increaseing counter appended to its name.</span><br><span class="line">delete(path, version), continue when the version matches.</span><br><span class="line">exists(path, watch), the watch flag enables client to set a watch on the znode.</span><br><span class="line">getData(path, watch), watch flag works the same way as exists().</span><br><span class="line">setData(path, data, version), continue when the version matches.</span><br><span class="line">getChildren(path, watch).</span><br><span class="line">sync(path), flush all the pending updates.</span><br></pre></td></tr></table></figure>
<p>All methods have both sync and async version, and <strong>ZooKeeper client</strong> guarantees that the corresponding callbacks for each operation are invoked in order.</p>
<p>Refer to the paper to see example primitives implemented by these APIs, including configration management, group membership, read/write locks, etc.</p>
<h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>ZooKeeper provides high availability by replicating the data on each server. For recoverability, it forces writes to be on the disk media before they are applied to the in-memory database. And it will keep a replay log of commited operations and generate periodic snapshots of the in-memory database.</p>
<p>For read request, they are serviced from the local replica, the local replica is guaranteed to be not diverged, although at any point in time some servers have applied more transactions than others. This will introduce problem that a read operation might return stale value. To gurantee a read operation retrieves the latest updated value, a client calls sync followed by a read operation.</p>
<p>For write request, they are forwarded to a single server, called the leader. The leader executes the request and broadcast the change to followers through Zab, an atomic broadcast protocol. Zab uses majority quorums to decide on a proposal and provides stronger order guarantees than regular atomic broadcast. Write ahead log is used to keep track of all changes to the database. Zab normally only deliver messages in order and exactly once, but may redeliver a message during recovery. Because the idempotent transaction is used, the end state is still same as long as they delivered in order.</p>
<p>When taking snapshot of a ZooKeeper server, the server state is not locked, instead, it depth frist scan of the tree and atomically reading each znode and write them to disk. The result might not correspond to the state of ZooKeeper at any point in time since some subsets of the state changes are delivered during the generation of the snapshot. However, since state changes are idempotent, we can apply it multiple times as long as they are in order.</p>
<p>Servers process writes in order and do not process other wirtes or reads concurrently. This ensure strict succession of notifications. Note that servers handle notification locally, only the server that a client is connected to tracks and triggers notification for that client.</p>
<p>Each read reqeust is processed and tagged with a zxid that corresponds to the last transaction seen by the server. If the client needs to connect to a new server, the new server ensures that is view of the ZooKeeper data is at least as recent as the view of the client by checking the last zxid of the client against its last zxid. And the connection won’t be establised until the server has caught up. The client is guarateed to be able to find another server that has a recent view of the system since the client only sees changes that have been replicated to a majority of the ZooKeeper servers.</p>
<p>ZooKeeper uses timeouts to detect client session failures. If the client cannot communicate with a server to send a request, it connects to a differernt server to re-establish the session.</p>
]]></content>
      <categories>
        <category>System Infrastructure</category>
        <category>Coordination Service</category>
      </categories>
      <tags>
        <tag>Distributed System</tag>
        <tag>Infrastructure</tag>
        <tag>Paper Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>于是开始奔跑</title>
    <url>/2019/12/08/run_with_the_wind/</url>
    <content><![CDATA[<p>我很佩服三浦紫苑，讲好一个故事本身就很不简单，她却偏偏选择依托在编纂辞典《编舟记》或者长跑《强风吹拂》这种让人听上去就觉得枯燥乏味的事物上，然后将一切娓娓道来。相较于其他运动而言，跑步确实听上去不那么让人热血沸腾，不像足篮排那样典型的热血物语，它并不能够给人带来和对手厮杀的压迫感，和赢得比赛、击败对手的畅快感，而更多的时候是一种与自我的搏斗。就像在动画中所说的，箱根驿传的后半段棒次奔跑在路上的时候可能一个人都看不见，所能听见的只有自己的呼吸和心跳。但正是这种习惯在孤独中让自己变得强大的姿态，才是这项运动的迷人之处。<br><a id="more"></a></p>
<p><img src="/images/haiji.png" alt></p>
<p>灰二是一切的开端，从大一到大四，一手组建出了宽政大的田径队，操办了所有队友的训练和饮食，以至于在他因过度劳累而晕倒的时候，大家才突然明白他到底付出了多少。</p>
<p>他是一个如此完美的领导者和行动派，所以才能对处在低谷的king说出“你是为我们存在的，而我也是为你们存在的”这样的话语，才能够在阿走不断地质疑声中保持团队的步调。</p>
<p>可是他又觉得自己是如此的弱小，在某个时间点，他也会怀疑自己是不是过于严苛，可能无法全员取得预选赛的资格。</p>
<p>“你知道对长跑选手来说，最棒的赞美是什么吗？是快吗？不是，是强。光跑的快没办法在长跑中脱颖而出。天候，场地，比赛的发展，体能，还有自己的精神状态——长跑选手必须冷静分析这些要素，即使面对再大的困难，也要坚韧不拔的突破难关。”</p>
<p>灰二是这部作品最懂得何谓强大的人，罗曼罗兰说过，这世上只有一种英雄主义，就是认清生活的真相后仍然热爱它。作为一个普通人。经历过漫长的低谷，不得不远离跑步，却一直挣扎着想要追上曾经的自己，我想他这就是对这句话最好的注解吧。这积蓄已久的不甘和遗憾是如此地强烈，才能让他在最后一棒中压抑住让他今后再也无法跑步的膝盖伤痛，以区间第二的成绩让宽政大进入前十。</p>
<p>你亲手开启了这个故事，并为它写上了最美的结局。</p>
<p>你明明已经是个如此坚强的跑者了，却依然无法战胜人生。</p>
<p><img src="/images/king.png" alt></p>
<p>King就是我们自己。</p>
<p>生活和工作上的压力让人无处遁形。于是我们觉得不能再像孩子一样无忧无虑了，不再年轻，没有放纵的资本。</p>
<p>看着大家为了箱根驿传这种不切实际的事情努力的身影，甚至还会嘲讽几句。</p>
<p>自己，还有更重要的事情要做；自己，并不属于这里。</p>
<p>所以我们选择关闭自己的门，和他人隔绝起来，然后把这叫做长大。</p>
<p>可是我却无法讨厌这样的king，因为我无法讨厌那个弱小的自己。</p>
<p>但是我想king是很幸运的，因为他并不是孤独的国王。</p>
<p>跑步并不能让你找到工作，但它可能成为一个契机。</p>
<p>停下来，就会感到不安，我们都有过这样的时期。</p>
<p>只有在跑步的时候，我才感觉自己是在前进的。</p>
<p>所以向前跑吧，尽管不知道有什么样的未来在那边等着，但如果不收拾好心情重新出发的话，是无法到达的。</p>
<p><img src="/images/yuki.png" alt></p>
<p>阿雪是这部作品最理性的人，他清楚地知道自己想要的是什么。</p>
<p>父亲的离世让他过早地成熟起来，眼见母亲独自一人日复一日地工作到深夜，将他拉扯成人，所以自己也决定早日找到一份安稳的工作，让母亲过上好日子。一直准备参加司法考试并在毕业之前通过，这之间的困难，大家应该都心知肚明，但也不见阿雪对别人提起。</p>
<p> 但母亲再婚的决定却让阿雪收到了巨大的打击，明明母亲已经获得了幸福，却和自己的设想不一样。母亲再婚之后很快就有了第二个孩子，自己似乎并没有办法融入新的家庭，于是考上大学就决定搬出去，也没有回过几次家。</p>
<p>但看到为自己特地赶来加油的家人们，心里那微不足道的芥蒂也开始慢慢融化了。他们一直都把自己当作家人，然而我却一直没有对他们敞开心扉。</p>
<p>跑起来，真的可以改变很多事情，在意想不到的地方。</p>
<p>在跑第六区间的时候，借着山路之力，阿雪也曾产生过“这样跑下去，是不是就能追上阿走”的想法，也似乎明白了对跑步的热爱从何而来。 但他也清楚地知道那是一条危险的、充满荆棘的道路，自己的未来并不在那里。</p>
<p>再快两秒就可以拿到区间赏了，但那两秒，是自己永远都无法超越的两秒。</p>
<p>不被选中的人是注定无法取得胜利的，那么他们一直跑下去的理由是什么呢？</p>
<p>但是不跑起来，是无法看到这个美丽的世界的，即使深知自己今日就要和它道别。</p>
<p><img src="/images/kakeru.png" alt></p>
<p>阿走的成长贯穿了整个作品的主线。</p>
<p>因为看不下去教练对待队友的方式爆发冲突而远离赛场，得不到任何人的理解，甚至连自己的队友也因为被禁赛而迁怒于他。</p>
<p>失去了保送田径名校的资格，进入了宽政大。甚至连自己的生活费也挥霍一空，只能靠偷便利店的面包裹腹。</p>
<p>那种压到你喘不过气的绝望，灰二也曾经历过。所以他才会再遇到阿走的时候那么确信，自己找到了第十个人。</p>
<p>但自己不相信仅仅凭借这随意拼凑的十个人可以站上去往箱根的赛场，怀疑、争吵、责备，被过去所束缚的走似乎并没有办法跑出笼罩在前方的阴霾。</p>
<p>尽管自己依然在不停的奔跑，但好像在逃避着什么，成绩没有提高，自己也日复一日地更加焦虑。</p>
<p>但幸好他有温暖的竹青庄，队友的宽容，学长的开导，和自己亲眼目睹的所有人为了同一个目标而奔跑的身姿。</p>
<p>因为你总是跑在前面，所以才看不到啊，在你身后拼命想追上你的我们。</p>
<p>于是阿走也开始学会关心他人，学会停下来，为奔跑的人呐喊。这是自己独自奔跑时没有过的经历，这是只有和大家一起奔跑时才能看到的风景。</p>
<p>所以当阿走发自内心地说出“我想我们这十个人，一起参加箱根驿传”的时候，我哭了，真好啊，藏原走，你遇到了那群把你变的更好的人。</p>
<p>三浦紫苑想讲的是人生。人生并不是一场马拉松，大家的起点并不相同，也并没有终点可言，但是我们却切切实实地奔跑在路上。可能孤独了许久，又或是遇到了志同道合的伙伴，就像是竹青庄的十个人，处在人生不同的阶段，怀抱着不同的理由，但大家还是一起站上了箱根驿传的赛场，传递着属于自己的一棒。</p>
<p>为什么要跑步？这是竹青庄一众最开始的问题，直到结尾作品也没有给我们一个明确的答案，但最后似乎所有人都收获了什么。</p>
<p>不是因为喜欢所以才认真，而是想着认真起来，说不定就喜欢上了。</p>
<p>因为奔跑的时候，我才感觉自己是纯净的。</p>
<p>因为现实并不会消失，那干脆不要逃避，和现实一起奔跑。</p>
<p>因为想跑的更快，知道自己的极限在哪里。</p>
<p>因为跑起来，才能看到之前不曾见过的风景。</p>
<p>开始跑步的原因可以有很多，坚持下去的理由也不尽相同，即使一直奔跑也会有停下来的一天。但是至少现在，请一直奔跑下去吧。也许并不知道前方会有什么风景，会遇到什么人，但是也请一直奔跑下去，因为我们现在所处的生活，就是我们的跑道。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo: Adding PV/UV  counters to NexT theme</title>
    <url>/2019/03/18/hexo_next_page_user_views/</url>
    <content><![CDATA[<h2 id="Site-PV-UV"><a href="#Site-PV-UV" class="headerlink" title="Site PV/UV"></a>Site PV/UV</h2><p>NexT supports integration with different metrics/analytics services, which you can check on their <a href="https://theme-next.iissnan.com/third-party-services.html#analytics-system" target="_blank" rel="noopener">website</a>. To track the PV/UV for the whole site, we choose <a href="http://ibruce.info/2015/04/04/busuanzi/" target="_blank" rel="noopener">busuanzi</a>, since it supports displaying those information on your webpage.<br><a id="more"></a></p>
<h3 id="Install-busuanzi-js"><a href="#Install-busuanzi-js" class="headerlink" title="Install busuanzi.js"></a>Install busuanzi.js</h3><p>NexT already integrates busuanzi, but based on their <a href="http://ibruce.info/2015/04/04/busuanzi/" target="_blank" rel="noopener">website</a>, busuanzi has to change their host name for some reasons and the old one is not compatibale anymore, we have to fix this problem by ourselves. To fix it, simply navigate to <code>themes/next/layout/_third-party/analytics/busuanzi-counter.swig</code> and change<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;script async src=<span class="string">"//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure></p>
<p>to<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;script async src=<span class="string">"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="Congifure-NexT"><a href="#Congifure-NexT" class="headerlink" title="Congifure NexT"></a>Congifure NexT</h3><p>To enable busuanzi in NexT, we need to configure <code>_config.yml</code> under <code>themes/next</code>. Search for <code>busuanzi_count</code> and modify based on your requirement<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">busuanzi_count:</span><br><span class="line">  <span class="comment"># count values only if the other configs are false</span></span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  <span class="comment"># custom uv span for the whole site</span></span><br><span class="line">  site_uv: <span class="literal">true</span></span><br><span class="line">  site_uv_header: &lt;i class=<span class="string">"fa fa-user"</span>&gt;&lt;/i&gt;</span><br><span class="line">  site_uv_footer: </span><br><span class="line">  <span class="comment"># custom pv span for the whole site</span></span><br><span class="line">  site_pv: <span class="literal">true</span></span><br><span class="line">  site_pv_header: &lt;i class=<span class="string">"fa fa-eye"</span>&gt;&lt;/i&gt;</span><br><span class="line">  site_pv_footer:</span><br><span class="line">  <span class="comment"># custom pv span for one page only</span></span><br><span class="line">  page_pv: <span class="literal">false</span></span><br><span class="line">  page_pv_header: &lt;i class=<span class="string">"fa fa-file-o"</span>&gt;&lt;/i&gt;</span><br><span class="line">  page_pv_footer:</span><br></pre></td></tr></table></figure></p>
<p>The above configuration only enables site_uv and site_pv, you can also customize the header and footer to make it more expressive. I disabled the page_pv since it only supports displaying visitors in the artical page, which means you can’t see it in home page, and we have a better replacement for it.<br>Update the settings and run <code>hexo s</code>, you will see the data in the footer:</p>
<p><img src="/images/site_pv_uv.png" alt></p>
<p>It currently displays all the counts to <code>http://localhost:4000</code>, once you deploy it, you will see the actual data of your website.</p>
<h2 id="Page-PV"><a href="#Page-PV" class="headerlink" title="Page PV"></a>Page PV</h2><p>To implement page pv counter, we need the corresponding backend service. Here, we choose <a href="https://leancloud.cn/" target="_blank" rel="noopener">LeanCloud</a> which is well supported by NexT.</p>
<h3 id="Setup-LeanCloud"><a href="#Setup-LeanCloud" class="headerlink" title="Setup LeanCloud"></a>Setup LeanCloud</h3><p>Create a LeanCloud account and then create a new application with the name you want</p>
<p><img src="/images/lean_cloud.png" alt></p>
<p>Click the application and create a new class with name <code>Counter</code> and set the ACL permission to be unlimited</p>
<p><img src="/images/lean_cloud_counter.png" alt></p>
<p>This creates a new DB table to store the page view counter information for each of your article, the key is the combination of you title and create time. You can also manually modify each data entry to change the actually number.</p>
<h3 id="Configure-NexT"><a href="#Configure-NexT" class="headerlink" title="Configure NexT"></a>Configure NexT</h3><p>Open <code>_config.yml</code> under <code>themes/next</code> and search for leancloud<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">leancloud_visitors:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  app_id: **your_app_id**</span><br><span class="line">  app_key: **your_app_key**</span><br></pre></td></tr></table></figure></p>
<p>You can find the <code>app_id</code> and <code>app_key</code> under settings in you LeanCloud application</p>
<p><img src="/images/lean_cloud_app_key.png" alt></p>
<p>Once you deploy the change, you will see the new page visitor counter in your articles.</p>
<p><img src="/images/page_pv.png" alt></p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>JavaScript</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>JavaScript</tag>
        <tag>NexT</tag>
      </tags>
  </entry>
  <entry>
    <title>Create your own blog with Hexo and Github Pages</title>
    <url>/2019/03/17/hexo_github_pages_blog/</url>
    <content><![CDATA[<h2 id="Set-up-local-development-environment-on-MacOS"><a href="#Set-up-local-development-environment-on-MacOS" class="headerlink" title="Set up local development environment on MacOS"></a>Set up local development environment on MacOS</h2><h3 id="Install-Node-js"><a href="#Install-Node-js" class="headerlink" title="Install Node.js"></a>Install Node.js</h3><p>Hexo is based on Node.js which can be installed <a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">here</a>. It comes with npm, once the installation is done, run the following commands to make sure it is installed successfully<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<h3 id="Install-Git"><a href="#Install-Git" class="headerlink" title="Install Git"></a>Install Git</h3><p>Follow the <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git" target="_blank" rel="noopener">steps</a> to install Git on your machine and verify by running<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git --version</span><br><span class="line">git version 2.17.2 (Apple Git-113)</span><br></pre></td></tr></table></figure></p>
<h3 id="Install-Hexo"><a href="#Install-Hexo" class="headerlink" title="Install Hexo"></a>Install Hexo</h3><p>Hexo can be installed from npm<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo npm install -g hexo</span><br></pre></td></tr></table></figure></p>
<p>Create your personal blog folder, cd into it. And run the following command to initialze and install all required packages<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init</span><br><span class="line">sudo npm install</span><br></pre></td></tr></table></figure></p>
<p>Once it is done, run<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure></p>
<p><code>hexo generate</code> or <code>hexo g</code>  will generate all static files, and <code>hexo server</code> or <code>hexo s</code> starts a local server and you can navigate to <code>http://localhost:4000</code> in browser to see your blog. Once the local server is started, hexo will watch for file updates automatically, so you don’t need to restart the server, simply refreshing the page and you will see the changes.</p>
<h2 id="Create-a-Github-Pages-project"><a href="#Create-a-Github-Pages-project" class="headerlink" title="Create a Github Pages project"></a>Create a Github Pages project</h2><p>What is Github Pages? According to the official website:</p>
<blockquote>
<p>GitHub Pages is a static site hosting service designed to host your personal, organization, or project pages directly from a GitHub repository</p>
</blockquote>
<p>As stated above, GitHub Pages is a static site hosting service, which means it doesn’t support server side programming. But it is good enough for building a personal blog, people may want to add some cool dynamic website features, which won’t be a problem. Hexo and different thirdparty tools can help us with it, we will talk about it later.<br>To use Github Pages, we need to create and configure our github account, we won’t dive deep into this part, there are a lot of related resouces can be easily googled. Once the Github account is set up, create a repository named as <code>&lt;username&gt;.github.io</code>.</p>
<h2 id="Link-Github-Pages-project-to-your-local-repository"><a href="#Link-Github-Pages-project-to-your-local-repository" class="headerlink" title="Link Github Pages project to your local repository"></a>Link Github Pages project to your local repository</h2><p>This can be easily done by modifying the config file. To do that, cd into you blog folder and open <code>_config.yml</code> with whatever text editor you like, and adding the following deploy configration to the file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repository: https://github.com/&lt;username&gt;/&lt;username&gt;.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure></p>
<p>To deploy on server, we need to install git deployer by<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></p>
<p>then run<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure></p>
<p>to deploy your project. Every time after you make some changes, you can follow the workflow above to view your changes locally then deploy. If you can’t see the changes after depolyment, you can run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br></pre></td></tr></table></figure></p>
<p>to clean the cached and generated files.</p>
<h2 id="Select-a-Theme"><a href="#Select-a-Theme" class="headerlink" title="Select a Theme"></a>Select a Theme</h2><p>Hexo has a variety of themes you can select from the <a href="https://hexo.io/themes/index.html" target="_blank" rel="noopener">offical website</a>. This blog is powered by <a href="https://github.com/theme-next/hexo-theme-next" target="_blank" rel="noopener">NexT</a>. To install it, cd into your blog folder and run<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure></p>
<p>This will clone the NexT project to your local repository. To enable the new theme, open <code>_config.yml</code>, under <code>theme</code>,  change <code>landscape</code> to <code>next</code> and deploy it.</p>
<p>The next article will discuss about theme configuration and third party integration tools.</p>
]]></content>
      <categories>
        <category>Programming</category>
        <category>JavaScript</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
</search>
